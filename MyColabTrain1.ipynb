{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3.7 TensorFlow","language":"python","name":"keras"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"MyColabTrain1.ipynb","provenance":[{"file_id":"1C6_w4YsbRcb9fLC5SWUW4mTCW-ep8h44","timestamp":1577865465258}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"359bbb5a666f4d17a7bd91015ac41132":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":["widget-interact"],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fab491ad759f419982ed2115d69ed873","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1c457c089d324d21a8f8c4e1861ee823","IPY_MODEL_9e82634ac2384812966173e4edd7a288"]}},"fab491ad759f419982ed2115d69ed873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c457c089d324d21a8f8c4e1861ee823":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","state":{"_view_name":"IntSliderView","style":"IPY_MODEL_0283bc27cc8c4adba5f8de8ad989ce9d","_dom_classes":[],"description":"x","step":1,"_model_name":"IntSliderModel","orientation":"horizontal","max":15,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":-5,"continuous_update":true,"readout_format":"d","description_tooltip":null,"readout":true,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b3f251fe7a746d49de3c6bddcbfae87"}},"9e82634ac2384812966173e4edd7a288":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","state":{"_view_name":"OutputView","msg_id":"","_dom_classes":[],"_model_name":"OutputModel","outputs":[{"output_type":"display_data","metadata":{"tags":[]},"text/plain":"5"}],"_view_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_view_count":null,"_view_module_version":"1.0.0","layout":"IPY_MODEL_e8dcec299a544c50bbc26794abaa13fb","_model_module":"@jupyter-widgets/output"}},"0283bc27cc8c4adba5f8de8ad989ce9d":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","state":{"_view_name":"StyleView","handle_color":null,"_model_name":"SliderStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4b3f251fe7a746d49de3c6bddcbfae87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"oYDeKNpPT-VR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":894},"outputId":"7e4e0f5d-739f-4295-8ea3-5d21701a0c17","executionInfo":{"status":"ok","timestamp":1578481785361,"user_tz":-420,"elapsed":115991,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["imagesFolder = '/home/ImageNetPart/'\n","%tensorflow_version 2.x\n","# %rm Data/*.dat\n","!find /home -name *.dat\n","\n","def initColab_Full():\n","    from google.colab import drive\n","    # !set | more\n","    drive.mount('/home/gdrive')\n","    %cd \"/home/gdrive/My Drive/Visualiz_Zeiler\"\n","\n","    !pip uninstall imageio --yes\n","    !pip install imageio\n","    !pip uninstall keras --yes\n","    !pip install keras\n","\n","    !df -hm | grep overlay\n","    !unzip VKIImageNetPart_TrainTestDivided.zip -d $imagesFolder >/dev/null\n","    !df -hm\n","    %mv \"$imagesFolder\"Test \"$imagesFolder\"test\n","    %mv \"$imagesFolder\"Train \"$imagesFolder\"train\n","\n","    %ls -l \"/home/ImageNetPart/test/Baltimore oriole/2543\"*\n","    path = imagesFolder + 'train/baseball/2832539985_13d806a911'\n","    # %ls -l \"$path\"* \n","    %mv \"$path\"\".jpg\" \"$path\"\".png\"\n","    %ls -l \"$path\"* \n","\n","    path = imagesFolder + 'test/Baltimore oriole/2543362638_8d77863b4c'\n","    %mv \"$path\"\".jpg\" \"$path\"\".png\"\n","    %ls -l \"$path\"* \n","    \n","def initCurRuntime():\n","    %cd \"/home/gdrive/My Drive/Visualiz_Zeiler\"\n","    # %rm *\\(1\\)*\n","    # %ls *Lo* -l\n","    # %pwd\n","    # %rm *.h5\n","    # %pip freeze >req.txt\n","\n","    %matplotlib inline\n","    %mkdir -p \"Logs2/src\"\n","    %cp -f ./*py* Logs2/src/\n","\n","    %mkdir QtLogs\n","\n","initColab_Full()    # Mounts Google drive and unzips images\n","initCurRuntime()\n","\n","from VisColabUtils import *\n","\n","# path = '2/10'\n","# !echo \"echo  $path\"\"*\"\n","# %mv \"$path\"*.png \"$path\"\".pn_g\"\n","# # !mv \"$path\"\"*.jpg\" \"$path\"\".png\"\n","# %ls \"$path\"*"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /home/gdrive\n","/home/gdrive/My Drive/Visualiz_Zeiler\n","Uninstalling imageio-2.4.1:\n","  Successfully uninstalled imageio-2.4.1\n","Collecting imageio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/de/f7f985018f462ceeffada7f6e609919fbcc934acd9301929cba14bc2c24a/imageio-2.6.1-py3-none-any.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.3.0)\n","Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from imageio) (1.17.4)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.46)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: imageio\n","Successfully installed imageio-2.6.1\n","Uninstalling Keras-2.2.5:\n","  Successfully uninstalled Keras-2.2.5\n","Collecting keras\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n","\u001b[K     |████████████████████████████████| 378kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from keras) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /tensorflow-2.1.0/python3.6 (from keras) (1.13.0)\n","Requirement already satisfied: numpy>=1.9.1 in /tensorflow-2.1.0/python3.6 (from keras) (1.17.4)\n","Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-2.1.0/python3.6 (from keras) (1.0.8)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /tensorflow-2.1.0/python3.6 (from keras) (1.1.0)\n","Installing collected packages: keras\n","Successfully installed keras-2.3.1\n","overlay            70044 31927     34517  49% /\n","Filesystem     1M-blocks  Used Available Use% Mounted on\n","overlay            70044 33771     32673  51% /\n","tmpfs                 64     0        64   0% /dev\n","tmpfs              13064     0     13064   0% /sys/fs/cgroup\n","tmpfs              13064     1     13064   1% /var/colab\n","/dev/sda1          76392 38282     38095  51% /opt/bin\n","shm                12672     1     12672   1% /dev/shm\n","tmpfs              13064     0     13064   0% /proc/acpi\n","tmpfs              13064     0     13064   0% /proc/scsi\n","tmpfs              13064     0     13064   0% /sys/firmware\n","drive              15360 10875      4486  71% /home/gdrive\n","-rw-r--r-- 1 root root 289436 Nov 11 19:32 '/home/ImageNetPart/test/Baltimore oriole/2543362638_8d77863b4c.jpg'\n","-rw-r--r-- 1 root root 309356 Nov 11 18:47 /home/ImageNetPart/train/baseball/2832539985_13d806a911.png\n","-rw-r--r-- 1 root root 289436 Nov 11 19:32 '/home/ImageNetPart/test/Baltimore oriole/2543362638_8d77863b4c.png'\n","/home/gdrive/My Drive/Visualiz_Zeiler\n","cp: -r not specified; omitting directory './__pycache__'\n","mkdir: cannot create directory ‘QtLogs’: File exists\n","2.1.0-rc1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ROZwYrztT-Vh","colab_type":"code","colab":{}},"source":["# print(controlObj.netWrapper.imageDataset.testSubset._loadFilesTree())\n","# print(controlObj.netWrapper.imageDataset.trainSubset._loadFilesTree())\n","# for im in controlObj.netWrapper.imageDataset.testSubset.imagesFileNames:\n","#     if im.find('2543') >= 0:\n","#         print(im)\n","\n","# !pip uninstall matplotlib python-qt imgaug\n","# !python -m pip install --upgrade pip\n","# !pip install matplotlib\n","# !pip install python-qt4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvVUCp5qT-Vq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["359bbb5a666f4d17a7bd91015ac41132","fab491ad759f419982ed2115d69ed873","1c457c089d324d21a8f8c4e1861ee823","9e82634ac2384812966173e4edd7a288","0283bc27cc8c4adba5f8de8ad989ce9d","4b3f251fe7a746d49de3c6bddcbfae87"]},"outputId":"b3d6d19a-4a32-4557-8c78-0ec38c039dc1","executionInfo":{"status":"ok","timestamp":1578481786627,"user_tz":-420,"elapsed":117084,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["import ipywidgets as widgets\n","from ipywidgets import interact, interactive, fixed, interact_manual\n","@interact   # Doesn't work now at VKI's GeForce, works at CoLab\n","def f(x=5):\n","    image = controlObj.imageDataset.getImage(x, 'cropped')\n","    imshow(image);\n","    return x\n","# interact(f, x=10);\n","\n","imageNum = 8\n","# image = controlObj.imageDataset.getImage(imageNum, 'cropped')\n","# imshow(image);"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"359bbb5a666f4d17a7bd91015ac41132","version_minor":0,"version_major":2},"text/plain":["interactive(children=(IntSlider(value=5, description='x', max=15, min=-5), Output()), _dom_classes=('widget-in…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"GxF_ZHVvT-Vw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9e73a576-e058-4bda-ac47-aed16dfc7053","executionInfo":{"status":"ok","timestamp":1578481801041,"user_tz":-420,"elapsed":131390,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["epochNum = -3\n","print(tf.__version__)\n","print(controlObj.getSelectedEpochNum())\n","layerName = 'conv_11'\n","activations, drawMode, stdData = controlObj.getActivationsData(epochNum, imageNum, layerName)\n","actImage = layoutLayersToOneImage(np.sqrt(activations), colCount, margin)\n","print(activations.shape, actImage.shape)\n","imshow(actImage);"],"execution_count":4,"outputs":[{"output_type":"stream","text":["seconds from start (passed microseconds)\n","2.1.0-rc1\n","5.503 (    77.00) 153\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 227, 227, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv_11 (Conv2D)                (None, 74, 74, 192)  37056       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 74, 74, 96)   0           conv_11[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 74, 74, 96)   0           conv_11[0][0]                    \n","__________________________________________________________________________________________________\n","conv_12_0 (Conv2D)              (None, 35, 35, 192)  460992      lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv_12_1 (Conv2D)              (None, 35, 35, 192)  460992      lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","spatial_dropout2d_1 (SpatialDro (None, 35, 35, 192)  0           conv_12_0[0][0]                  \n","__________________________________________________________________________________________________\n","spatial_dropout2d_2 (SpatialDro (None, 35, 35, 192)  0           conv_12_1[0][0]                  \n","__________________________________________________________________________________________________\n","cross_chan_norm_10 (Lambda)     (None, 35, 35, 192)  0           spatial_dropout2d_1[0][0]        \n","__________________________________________________________________________________________________\n","cross_chan_norm_11 (Lambda)     (None, 35, 35, 192)  0           spatial_dropout2d_2[0][0]        \n","__________________________________________________________________________________________________\n","conv_13_0 (Conv2D)              (None, 35, 35, 192)  331968      cross_chan_norm_10[0][0]         \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 2)            0                                            \n","__________________________________________________________________________________________________\n","conv_13_1 (Conv2D)              (None, 35, 35, 192)  331968      cross_chan_norm_11[0][0]         \n","__________________________________________________________________________________________________\n","add_123_0 (Add)                 (None, 35, 35, 192)  0           spatial_dropout2d_1[0][0]        \n","                                                                 conv_13_0[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 1)            0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","add_123_1 (Add)                 (None, 35, 35, 192)  0           spatial_dropout2d_2[0][0]        \n","                                                                 conv_13_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 1)            0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 35, 35, 192)  0           add_123_0[0][0]                  \n","                                                                 lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_2 (Multiply)           (None, 35, 35, 192)  0           add_123_1[0][0]                  \n","                                                                 lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 192)  0           multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 192)  0           multiply_2[0][0]                 \n","__________________________________________________________________________________________________\n","conv_1_adds (Concatenate)       (None, 17, 17, 384)  0           max_pooling2d_1[0][0]            \n","                                                                 max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","cross_chan_norm_1u (Lambda)     (None, 17, 17, 384)  0           conv_1_adds[0][0]                \n","__________________________________________________________________________________________________\n","conv_21 (Conv2D)                (None, 15, 15, 768)  2654976     cross_chan_norm_1u[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 15, 15, 768)  3072        conv_21[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 15, 15, 768)  3072        conv_21[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 15, 15, 384)  0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 15, 15, 384)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv_22_0 (Conv2D)              (None, 13, 13, 384)  1327488     lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv_22_1 (Conv2D)              (None, 13, 13, 384)  1327488     lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","spatial_dropout2d_3 (SpatialDro (None, 13, 13, 384)  0           conv_22_0[0][0]                  \n","__________________________________________________________________________________________________\n","spatial_dropout2d_5 (SpatialDro (None, 13, 13, 384)  0           conv_22_1[0][0]                  \n","__________________________________________________________________________________________________\n","cross_chan_norm_20 (Lambda)     (None, 13, 13, 384)  0           spatial_dropout2d_3[0][0]        \n","__________________________________________________________________________________________________\n","cross_chan_norm_21 (Lambda)     (None, 13, 13, 384)  0           spatial_dropout2d_5[0][0]        \n","__________________________________________________________________________________________________\n","conv_23_0 (Conv2D)              (None, 13, 13, 384)  1327488     cross_chan_norm_20[0][0]         \n","__________________________________________________________________________________________________\n","conv_23_1 (Conv2D)              (None, 13, 13, 384)  1327488     cross_chan_norm_21[0][0]         \n","__________________________________________________________________________________________________\n","add_223_0 (Add)                 (None, 13, 13, 384)  0           spatial_dropout2d_3[0][0]        \n","                                                                 conv_23_0[0][0]                  \n","__________________________________________________________________________________________________\n","add_223_1 (Add)                 (None, 13, 13, 384)  0           spatial_dropout2d_5[0][0]        \n","                                                                 conv_23_1[0][0]                  \n","__________________________________________________________________________________________________\n","spatial_dropout2d_4 (SpatialDro (None, 13, 13, 384)  0           add_223_0[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 1)            0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","spatial_dropout2d_6 (SpatialDro (None, 13, 13, 384)  0           add_223_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 1)            0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","multiply_3 (Multiply)           (None, 13, 13, 384)  0           spatial_dropout2d_4[0][0]        \n","                                                                 lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_4 (Multiply)           (None, 13, 13, 384)  0           spatial_dropout2d_6[0][0]        \n","                                                                 lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv_2_adds (Concatenate)       (None, 13, 13, 768)  0           multiply_3[0][0]                 \n","                                                                 multiply_4[0][0]                 \n","__________________________________________________________________________________________________\n","conv_3 (Conv2D)                 (None, 11, 11, 384)  2654592     conv_2_adds[0][0]                \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 384)    0           conv_3[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 5, 5, 384)    1536        max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 9600)         0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 384)          3686784     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 384)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 192)          73920       dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 192)          0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 24)           4632        dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 24)           0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","softmax (Activation)            (None, 24)           0           lambda_9[0][0]                   \n","==================================================================================================\n","Total params: 16,015,512\n","Trainable params: 16,011,672\n","Non-trainable params: 3,840\n","__________________________________________________________________________________________________\n","None\n","8.486 (2982498.00) Activations: (1, 192, 74, 74), max 50.6344 ([0, 153, 50, 28])\n","8.491 (  5481.00) (70, 74, 74) (606, 606)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gHQoQMxMT-V4","colab_type":"code","colab":{}},"source":["for i in range(0):\n","    activations = controlObj.netWrapper.getImageActivations('dense_2', i, epochNum)\n","    print(activations);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1B5e6kQfn8EA","colab_type":"code","colab":{}},"source":["def preprocess_image(image):\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  image = tf.image.resize(image, [192, 192])\n","  image /= 255.0  # normalize to [0,1] range\n","  return image\n","def load_and_preprocess_image(path):\n","  image = tf.io.read_file(path)\n","  return preprocess_image(image)\n","def load_and_preprocess_image_with_label(path, label):\n","  print(path)\n","  image = tf.io.read_file(path)\n","  print(image, label)\n","  return preprocess_image(image), label\n","\n","all_image_paths = [\"ImageNetPart/American crow/1003355_8d39d66686.jpg\", \n","                   \"ImageNetPart/barn owl/101715431_19d0b37108.jpg\"]\n","labels = ['crow', 'owl']\n","path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n","image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=1)\n","# for n, image in enumerate(load_image_ds.take(7)):\n","#     print(image)\n","    \n","label_ds = tf.data.Dataset.from_tensor_slices(labels)\n","ds = tf.data.Dataset.zip((image_ds, label_ds))\n","# ds = tf.data.Dataset.zip((path_ds, label_ds))\n","# for n, v in enumerate(ds.take(7)):\n","#     print(v)\n","ds = ds.repeat()\n","# ds = ds.map(load_and_preprocess_image_with_label, num_parallel_calls=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mIgxHv-GT-V_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4ff4bcb4-820f-435b-f4b2-2a1c072215e3","executionInfo":{"status":"ok","timestamp":1578481801370,"user_tz":-420,"elapsed":131512,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["# Internal dataset's check\n","import tensorflow as tf\n","print(tf.executing_eagerly())\n","ds = controlObj.imageDataset.getTfDataset('test') \n","# print(ds)\n","plt.figure(figsize=(8,8))\n","for n, val in enumerate(ds.take(3)):\n","    # ??val\n","    # print(val)\n","    imageNum = val[0].numpy()\n","    # classInd = val[1].numpy()\n","    classInd = val[1].numpy()\n","#     if imageNum % 1000 == 0:\n","#         print(val)\n","#     continue\n","    className = controlObj.imageDataset.getClassNameLabel(classInd) #.decode('ascii')\n","#     print(image.numpy().shape)\n","    ax = plt.subplot(4,4,n+1)\n","    plt.text(1.1, 0.5, '%s (%s)' % (className, str(classInd)),  \n","          transform = ax.transAxes)\n","    image = controlObj.imageDataset.getImage(imageNum, 'cropped', 'test')\n","    plt.imshow(image / 255.0)\n","    #   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.show()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["8.772 (280554.00) True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dpF8wFbFT-WH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":154},"outputId":"3d0fcfc1-f2c2-4820-a16c-e4c9b05e9ece","executionInfo":{"status":"ok","timestamp":1578481808451,"user_tz":-420,"elapsed":138518,"user":{"displayName":"MikFolding","photoUrl":"","userId":"18160343468927980342"}}},"source":["# Final (batched) datasets' check\n","# controlObj.netWrapper._initMainNet()\n","# print(controlObj.netWrapper)\n","trainImageNums = np.arange(1, controlObj.imageDataset.getImageCount('train') + 1)\n","testImageNums = np.arange(1, controlObj.imageDataset.getImageCount('test') + 1)\n","tfTrainDataset, tfTestDataset = controlObj.netWrapper.net._getTfDatasets(\n","                trainImageNums, testImageNums, 1000)\n","# tfDataset = tf.compat.v1.data.make_one_shot_iterator(tfDataset)\n","# ??tfDataset\n","\n","print(controlObj.imageDataset.getImageCount('train'))\n","if 1:\n","    plt.figure(figsize=(8,8))\n","    for n, val in enumerate(tfTrainDataset.take(2)):\n","        print(controlObj.netWrapper.getCacheStatusInfo(True))\n","        images = val[0].numpy()\n","    #     ??images\n","        print(images.shape)\n","        matrixImage = layoutLayersToOneImage(images, colCount, margin)\n","        imshow(matrixImage);\n","    #     imshow(images[0])\n","        plt.show()\n","\n","if 0:\n"," for n, val in enumerate(tfDataset.take(0)):\n","  # ??val\n","  image = val[0][0].numpy()\n","  # classInd = val[1].numpy()\n","  # className = controlObj.imageDataset.getClassNameByInd(classInd) #.decode('ascii')\n","  classVec = val[1][0].numpy()\n","  print(image.shape)\n","  ax = plt.subplot(4,4,n+1)\n","  plt.text(1.1, 0.5, str(classVec),  \n","          transform = ax.transAxes)\n","  plt.imshow(image /255.0)\n","#   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.show()\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["9.029 (256763.00) 12402\n","18.407 (9378447.00) acts: 4.01 MBs, images: 261 object(s), 0 + 0 in LRU lists, 48.74 MBs\n","18.431 ( 24226.00) (64, 227, 227, 3)\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["19.353 (921796.00) acts: 4.01 MBs, images: 282 object(s), 0 + 0 in LRU lists, 52.67 MBs\n","19.388 ( 34554.00) (64, 227, 227, 3)\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FY5IDOzLT-WP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a955bad7-cdeb-4eac-d78a-41bc42fae8de"},"source":["controlObj.netWrapper.imageCache.maxMemory = 4 << 30\n","controlObj.learnRate = 7e-5\n","controlObj.onDoItersPressed(1)\n","print(controlObj.netWrapper.getCacheStatusInfo(True))\n","controlObj.onDoItersPressed(20000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["29.253 (9865726.00) Cur control object epoch 0, wrapper - 153\n","29.398 (144616.00) Learning rate switched to 0.000070\n","Epoch 154/154\n"," - 40s - loss: 0.0277 - accuracy: 0.4662 - val_loss: 0.0257 - val_accuracy: 0.4594\n","168.118 (138719856.00) acts: 4.01 MBs, images: 4794 object(s), 199 + 0 in LRU lists, 848.06 MBs\n","168.243 (124701.00) Epoch 154: loss 0.02774, acc 0.4662, last 1 epochs: 44.4566 s\n","168.244 (  1611.00) Epoch 154 finished\n","168.245 (   762.00) Epoch 154: loss 0.02774, acc 0.4662, last 1 epochs: 44.4566 s\n","168.246 (  1022.00) acts: 4.01 MBs, images: 4794 object(s), 199 + 0 in LRU lists, 848.06 MBs\n","168.247 (   852.00) Cur control object epoch 154, wrapper - 153\n","Epoch 155/155\n"," - 22s - loss: 0.0270 - accuracy: 0.4927 - val_loss: 0.0233 - val_accuracy: 0.5469\n","245.620 (77372984.00) acts: 4.01 MBs, images: 6901 object(s), 247 + 512 in LRU lists, 1219.32 MBs\n","245.735 (115649.00) Epoch 155: loss 0.02700, acc 0.4927, last 1 epochs: 22.0566 s\n","Epoch 156/156\n"," - 21s - loss: 0.0268 - accuracy: 0.4875 - val_loss: 0.0216 - val_accuracy: 0.5625\n","317.309 (71573384.00) acts: 4.01 MBs, images: 8494 object(s), 303 + 512 in LRU lists, 1503.74 MBs\n","317.444 (134915.00) Epoch 156: loss 0.02680, acc 0.4875, last 1 epochs: 20.6220 s\n","Epoch 157/157\n"," - 19s - loss: 0.0282 - accuracy: 0.4635 - val_loss: 0.0269 - val_accuracy: 0.4844\n","384.423 (66979547.00) acts: 4.01 MBs, images: 9788 object(s), 153 + 512 in LRU lists, 1736.79 MBs\n","384.571 (147939.00) Epoch 157: loss 0.02820, acc 0.4635, last 1 epochs: 19.1728 s\n","Epoch 158/158\n"," - 18s - loss: 0.0277 - accuracy: 0.4625 - val_loss: 0.0231 - val_accuracy: 0.5391\n","448.940 (64368565.00) acts: 4.01 MBs, images: 10767 object(s), 318 + 512 in LRU lists, 1914.66 MBs\n","449.071 (131488.00) Epoch 158: loss 0.02766, acc 0.4625, last 1 epochs: 18.3894 s\n","Epoch 159/159\n"," - 28s - loss: 0.0273 - accuracy: 0.4793 - val_loss: 0.0242 - val_accuracy: 0.5312\n","542.438 (93367067.00) acts: 4.01 MBs, images: 11890 object(s), 5 + 512 in LRU lists, 2120.69 MBs\n","542.573 (134466.00) Epoch 159: loss 0.02731, acc 0.4793, last 1 epochs: 28.4186 s\n","Epoch 160/160\n"," - 47s - loss: 0.0279 - accuracy: 0.4607 - val_loss: 0.0263 - val_accuracy: 0.5359\n","692.341 (149768450.00) acts: 4.01 MBs, images: 13230 object(s), 204 + 512 in LRU lists, 2368.66 MBs\n","692.490 (148845.00) Epoch 160: loss 0.02787, acc 0.4607, last 1 epochs: 47.3682 s\n","Epoch 161/161\n"," - 82s - loss: 0.0277 - accuracy: 0.4670 - val_loss: 0.0244 - val_accuracy: 0.5297\n","945.217 (252726900.00) acts: 4.01 MBs, images: 14503 object(s), 433 + 512 in LRU lists, 2604.46 MBs\n","945.344 (126539.00) Epoch 161: loss 0.02772, acc 0.4670, last 1 epochs: 82.3421 s\n","Epoch 162/162\n"," - 97s - loss: 0.0278 - accuracy: 0.4651 - val_loss: 0.0237 - val_accuracy: 0.5072\n","1238.324 (292980301.00) acts: 4.01 MBs, images: 15065 object(s), 68 + 512 in LRU lists, 2708.59 MBs\n","1238.463 (139094.00) Epoch 162: loss 0.02779, acc 0.4651, last 1 epochs: 97.3699 s\n","Epoch 163/163\n"," - 96s - loss: 0.0278 - accuracy: 0.4731 - val_loss: 0.0251 - val_accuracy: 0.5210\n","1528.097 (289634254.00) acts: 4.01 MBs, images: 15237 object(s), 105 + 512 in LRU lists, 2740.28 MBs\n","1528.238 (140891.00) Epoch 163: loss 0.02779, acc 0.4731, last 1 epochs: 96.3509 s\n","Epoch 164/164\n"," - 96s - loss: 0.0277 - accuracy: 0.4689 - val_loss: 0.0282 - val_accuracy: 0.5463\n","1815.706 (287467612.00) acts: 4.01 MBs, images: 15287 object(s), 288 + 512 in LRU lists, 2749.58 MBs\n","1815.853 (147780.00) Epoch 164: loss 0.02767, acc 0.4689, last 1 epochs: 95.5510 s\n","Epoch 165/165\n"," - 95s - loss: 0.0277 - accuracy: 0.4636 - val_loss: 0.0228 - val_accuracy: 0.5373\n","2101.838 (285985019.00) Epoch 165: loss 0.02768, acc 0.4636, last 1 epochs: 95.0627 s\n","Epoch 166/166\n"," - 95s - loss: 0.0270 - accuracy: 0.4826 - val_loss: 0.0306 - val_accuracy: 0.5234\n","2387.611 (285772972.00) Epoch 166: loss 0.02704, acc 0.4826, last 1 epochs: 95.1141 s\n","Epoch 167/167\n"," - 95s - loss: 0.0275 - accuracy: 0.4838 - val_loss: 0.0260 - val_accuracy: 0.5403\n","2672.034 (284422327.00) Epoch 167: loss 0.02750, acc 0.4838, last 1 epochs: 94.8925 s\n","Epoch 168/168\n"," - 95s - loss: 0.0273 - accuracy: 0.4777 - val_loss: 0.0233 - val_accuracy: 0.5571\n","2957.785 (285751046.00) Epoch 168: loss 0.02729, acc 0.4777, last 1 epochs: 95.1656 s\n","Epoch 169/169\n"," - 95s - loss: 0.0271 - accuracy: 0.4885 - val_loss: 0.0238 - val_accuracy: 0.5276\n","3243.540 (285755104.00) Epoch 169: loss 0.02712, acc 0.4885, last 1 epochs: 95.1612 s\n","Epoch 170/170\n"," - 95s - loss: 0.0267 - accuracy: 0.4908 - val_loss: 0.0248 - val_accuracy: 0.5559\n","3528.930 (285389994.00) Epoch 170: loss 0.02667, acc 0.4908, last 1 epochs: 95.1222 s\n","Epoch 171/171\n"," - 95s - loss: 0.0269 - accuracy: 0.4890 - val_loss: 0.0267 - val_accuracy: 0.5084\n","3814.439 (285509394.00) Epoch 171: loss 0.02689, acc 0.4890, last 1 epochs: 94.9136 s\n","Epoch 172/172\n"," - 95s - loss: 0.0270 - accuracy: 0.4820 - val_loss: 0.0260 - val_accuracy: 0.5445\n","4100.494 (286055088.00) Epoch 172: loss 0.02704, acc 0.4820, last 1 epochs: 95.0212 s\n","Epoch 173/173\n"," - 95s - loss: 0.0268 - accuracy: 0.4930 - val_loss: 0.0224 - val_accuracy: 0.5439\n","4384.933 (284438891.00) Epoch 173: loss 0.02677, acc 0.4930, last 1 epochs: 95.0154 s\n","Epoch 174/174\n"," - 95s - loss: 0.0268 - accuracy: 0.4923 - val_loss: 0.0232 - val_accuracy: 0.5523\n","4670.069 (285135844.00) acts: 4.01 MBs, images: 15320 object(s), 349 + 512 in LRU lists, 2755.56 MBs\n","4670.201 (132251.00) Epoch 174: loss 0.02684, acc 0.4923, last 1 epochs: 95.0240 s\n","Epoch 175/175\n"," - 95s - loss: 0.0271 - accuracy: 0.4845 - val_loss: 0.0272 - val_accuracy: 0.5415\n","4955.046 (284844463.00) Epoch 175: loss 0.02707, acc 0.4845, last 1 epochs: 94.7423 s\n","Epoch 176/176\n"," - 95s - loss: 0.0267 - accuracy: 0.4890 - val_loss: 0.0251 - val_accuracy: 0.5547\n","5241.201 (286154733.00) Epoch 176: loss 0.02674, acc 0.4890, last 1 epochs: 95.1916 s\n","Epoch 177/177\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I-nrvlH1T-Wj","colab_type":"code","colab":{}},"source":["controlObj.learnRate = 7e-6\n","controlObj.onDoItersPressed(50000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkgTh-6vT-Wp","colab_type":"code","colab":{}},"source":["controlObj.learnRate = 7e-7\n","controlObj.onDoItersPressed(1000000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PCWi38pT-Wx","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(20,10))\n","columns = 5\n","for i in range(3):\n","    imshow(activations[i],cmap='Greys_r')   # Displays only one\n","#display(activations[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jacNQe7T-XA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JKCUGQ2ST-XI","colab_type":"code","colab":{}},"source":["def showImagesMatrix(data, col=2):\n","    fig = figure( figsize=(600, 300))\n","    number_of_files = len(data)\n","    print(number_of_files)\n","    row = number_of_files/col\n","    if (number_of_files%col != 0):\n","        row += 1\n","    for i in range(number_of_files):\n","        a=fig.add_subplot(row,col,i+1)\n","        # image = imread(mypath+'/'+list_of_files[i])\n","        axis('off')\n","        print('Image %d drawn' % i)\n","    # Very slow at the end\n","        \n","showImagesMatrix(activations[1:8])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVgS-QIyT-XN","colab_type":"code","colab":{}},"source":["for i in np.random.permutation(600)[:4]:\n","    count = count + 1\n","    plt.subplot(1, sample_size, count)\n","    plt.axhline('')\n","    plt.axvline('')\n","    plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n","    plt.imshow(X_train[i].reshape(28, 28), cmap=plt.cm.Greys)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzsueFfWT-XR","colab_type":"code","colab":{}},"source":["im = Image(filename=\"image/000644.jpg\", width=100, height=100)\n","im.shape()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSQCyhwzT-XX","colab_type":"code","colab":{}},"source":["![title](images/000644.png)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Yn9Lwf7T-Xd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mt9a8CdTT-Xn","colab_type":"code","colab":{}},"source":["from IPython.display import Image          # Displaying of multiple images. To check\n","from IPython.display import display\n","x = Image(filename='1.png') \n","y = Image(filename='2.png') \n","display(x, y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kNsWHJjCT-Xy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3VMha8dT-YB","colab_type":"code","colab":{}},"source":["out = widgets.Output(layout={'border': '1px solid black'})\n","with out:\n","    display(widgets.IntSlider())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNJf78MQT-YJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aV7K2NqxT-YP","colab_type":"raw"},"source":[""]}]}