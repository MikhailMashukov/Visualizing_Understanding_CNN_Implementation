{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0 [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# 15_4\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.getcwd()\n",
    "print(tf.__version__, tf.config.list_physical_devices('GPU'))\n",
    "# !pwd\n",
    "%matplotlib inline \n",
    "\n",
    "# from ipyexperiments import *\n",
    "# exp2 = IPyExperimentsPytorch()\n",
    "# from VisQtMain import *\n",
    "from VisJupyterNotUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !df -h\n",
    "# !cat /proc/cpuinfo\n",
    "# !top \n",
    "\n",
    "# import psutil\n",
    "\n",
    "# p = psutil.Process()\n",
    "# print(p.cpu_affinity())\n",
    "# p.cpu_affinity(range(0, 32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: -r not specified; omitting directory '/root/Visualiz_Zeiler/Data'\n",
      "cp: -r not specified; omitting directory '/root/Visualiz_Zeiler/ImageNetPart'\n",
      "cp: -r not specified; omitting directory '/root/Visualiz_Zeiler/QtLogs'\n",
      "cp: -r not specified; omitting directory '/root/Visualiz_Zeiler/__pycache__'\n",
      "AlexNetVisWrapper.py       MyImagesNetAnalysis.ipynb\n",
      "ChanConvModel.py           MyTrain1.ipynb\n",
      "ChanMatrixModel.py         MyUtils.py\n",
      "CorrelatAnalyzis.py        \u001b[0m\u001b[01;34mQtLogs\u001b[0m/\n",
      "\u001b[01;34mData\u001b[0m/                      SEResNeXt.py\n",
      "DataCache.py               VKIImageNetPart_TrainTestDivided.zip\n",
      "DeepOptions.py             VisColabUtils.py\n",
      "ImageModels.py             VisJupyterNotUtils.py\n",
      "ImageNet.py                VisQtMain.py\n",
      "\u001b[01;34mImageNetPart\u001b[0m/              VisUtils.py\n",
      "ImageNetsVisWrappers.py    \u001b[01;34m__pycache__\u001b[0m/\n",
      "MnistModel2.py             activations.py\n",
      "MnistModel5.py             alexnet.py\n",
      "MnistNet.py                alexnet_additional_layers.py\n",
      "MnistNetVisWrapper.py      alexnet_utils.py\n",
      "ModelUtils.py              decode_predictions.py\n",
      "MultActTops.py             deconvolution.py\n",
      "MyApolloImagesNetAn.ipynb  deconvolution_additional_layers.py\n",
      "MyApolloTrain1.ipynb       occlusion.py\n",
      "MyColabImagesNetAn.ipynb   validation.py\n",
      "MyColabTrain1.ipynb\n"
     ]
    }
   ],
   "source": [
    "# %rm -r ~/Visualiz_Zeiler/QtLogs/src\n",
    "%mkdir -p ~/Visualiz_Zeiler/QtLogs/src\n",
    "%cp -f ~/Visualiz_Zeiler/* ~/Visualiz_Zeiler/QtLogs/src/\n",
    "%ls ~/Visualiz_Zeiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137ce804a083495cab77ef02f6e604d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='x', max=15, min=-5), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "@interact   # Doesn't work now\n",
    "def f(x=5):\n",
    "    return x\n",
    "# interact(f, x=10);\n",
    "\n",
    "imageNum = 8\n",
    "image = controlObj.imageDataset.getImage(imageNum, 'cropped')\n",
    "# imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds from start (passed microseconds)\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 27, 27, 512)\n",
      "conv_22_1:  (None, 25, 25, 16, 64)\n",
      "conv_22_2:  (None, 25, 25, 32, 64)\n",
      "conv_24_1:  (None, 17, 17, 24, 64)\n",
      "conv_24_2:  (None, 17, 17, 12, 64)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 227, 227, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 111, 111, 128 18944       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 74, 74, 128)  0           conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cross_chan_norm_120 (Lambda)    (None, 74, 74, 128)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cross_chan_norm_121 (Lambda)    (None, 74, 74, 128)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 74, 74, 128)  512         cross_chan_norm_120[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 74, 74, 128)  512         cross_chan_norm_121[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 74, 74, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 74, 74, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_12_0 (Conv2D)              (None, 35, 35, 256)  409856      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_12_1 (Conv2D)              (None, 35, 35, 256)  409856      lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 35, 35, 256)  0           conv_12_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_2 (SpatialDro (None, 35, 35, 256)  0           conv_12_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 35, 256)  1024        spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 35, 35, 256)  1024        spatial_dropout2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_0 (Conv2D)              (None, 35, 35, 256)  590080      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_1 (Conv2D)              (None, 35, 35, 256)  590080      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_123_0 (Add)                 (None, 35, 35, 256)  0           spatial_dropout2d_1[0][0]        \n",
      "                                                                 conv_13_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_123_1 (Add)                 (None, 35, 35, 256)  0           spatial_dropout2d_2[0][0]        \n",
      "                                                                 conv_13_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 35, 35, 256)  0           add_123_0[0][0]                  \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 35, 35, 256)  0           add_123_1[0][0]                  \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_adds (Concatenate)       (None, 35, 35, 512)  0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 27, 27, 512)  0           conv_1_adds[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 27, 27, 512)  2048        lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 27, 27, 16, 3 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 27, 27, 32, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_22_1 (Conv3D)              (None, 25, 25, 16, 6 18496       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_22_2 (Conv3D)              (None, 25, 25, 32, 6 9280        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_23 (Concatenate)         (None, 25, 25, 48, 6 0           conv_22_1[0][0]                  \n",
      "                                                                 conv_22_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 25, 25, 3072) 0           concat_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 19, 19, 3072) 0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 19, 19, 3072) 12288       lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 19, 19, 24, 1 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 19, 19, 12, 2 0           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_24_1 (Conv3D)              (None, 17, 17, 24, 6 73792       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_24_2 (Conv3D)              (None, 17, 17, 12, 6 147520      reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 17, 17, 1536) 0           conv_24_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 17, 17, 768)  0           conv_24_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_25_1 (Conv2D)              (None, 16, 16, 512)  3146240     reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_25_2 (Conv2D)              (None, 16, 16, 512)  1573376     reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_3 (Concatenate)          (None, 16, 16, 1024) 0           conv_25_1[0][0]                  \n",
      "                                                                 conv_25_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 12, 12, 1024) 0           concat_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 12, 12, 1024) 4096        lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 10, 10, 192)  1769664     batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_3 (SpatialDro (None, 10, 10, 192)  0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 7, 7, 192)    0           spatial_dropout2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 5, 5, 384)    663936      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 3, 3, 384)    0           conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 3, 3, 384)    1536        lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3456)         0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          442496      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          33024       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 24)           6168        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 24)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 24)           0           lambda_11[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,925,848\n",
      "Trainable params: 9,914,328\n",
      "Non-trainable params: 11,520\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "10.960 (2608598.00) Activations: (1, 128, 111, 111), max 101.6902 ([0, 57, 2, 37])\n",
      "10.969 (  9144.00) (70, 111, 111) (902, 902)\n"
     ]
    }
   ],
   "source": [
    "epochNum = -3\n",
    "print(controlObj.getSelectedEpochNum())\n",
    "layerName = 'conv_11'\n",
    "activations, drawMode, stdData = controlObj.getActivationsData(epochNum, imageNum, layerName)\n",
    "actImage = layoutLayersToOneImage(np.sqrt(activations), colCount, margin)\n",
    "print(activations.shape, actImage.shape)\n",
    "imshow(actImage);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(0):\n",
    "    activations = controlObj.netWrapper.getImageActivations('dense_2', i, epochNum)\n",
    "    print(activations);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "  return image\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)\n",
    "def load_and_preprocess_image_with_label(path, label):\n",
    "  print(path)\n",
    "  image = tf.io.read_file(path)\n",
    "  print(image, label)\n",
    "  return preprocess_image(image), label\n",
    "\n",
    "all_image_paths = [\"ImageNetPart/American crow/1003355_8d39d66686.jpg\", \n",
    "                   \"ImageNetPart/barn owl/101715431_19d0b37108.jpg\"]\n",
    "labels = ['crow', 'owl']\n",
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=1)\n",
    "# for n, image in enumerate(load_image_ds.take(7)):\n",
    "#     print(image)\n",
    "    \n",
    "label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "# ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "# for n, v in enumerate(ds.take(7)):\n",
    "#     print(v)\n",
    "ds = ds.repeat()\n",
    "# ds = ds.map(load_and_preprocess_image_with_label, num_parallel_calls=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Internal dataset's check\n",
    "ds = controlObj.imageDataset.getTfDataset('test') \n",
    "# print(ds)\n",
    "plt.figure(figsize=(8,8))\n",
    "for n, val in enumerate(ds.take(3)):\n",
    "    # ??val\n",
    "#     print(val)\n",
    "    imageNum = val[0].numpy()\n",
    "    # classInd = val[1].numpy()\n",
    "    classInd = val[1].numpy()\n",
    "#     if imageNum % 1000 == 0:\n",
    "#         print(val)\n",
    "#     continue\n",
    "    className = controlObj.imageDataset.getClassNameLabel(classInd) #.decode('ascii')\n",
    "#     print(image.numpy().shape)\n",
    "    ax = plt.subplot(4,4,n+1)\n",
    "    plt.text(1.1, 0.5, '%s (%s)' % (className, str(classInd)),  \n",
    "          transform = ax.transAxes)\n",
    "    image = controlObj.imageDataset.getImage(imageNum, 'cropped', 'test')\n",
    "    plt.imshow(image / 255.0)\n",
    "    #   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Final (batched) datasets' check\n",
    "trainImageNums = np.arange(1, controlObj.imageDataset.getImageCount('train') + 1)\n",
    "testImageNums = np.arange(1, controlObj.imageDataset.getImageCount('test') + 1)\n",
    "tfTrainDataset, tfTestDataset = controlObj.netWrapper.net._getTfDatasets(\n",
    "                trainImageNums, testImageNums, 1000)\n",
    "# tfDataset = tf.compat.v1.data.make_one_shot_iterator(tfDataset)\n",
    "# ??tfDataset\n",
    "\n",
    "print(controlObj.imageDataset.getImageCount('train'))\n",
    "if 1:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for n, val in enumerate(tfTrainDataset.take(2)):\n",
    "        print(controlObj.netWrapper.getCacheStatusInfo(True))\n",
    "        images = val[0].numpy()\n",
    "    #     ??images\n",
    "        print(images.shape)\n",
    "        matrixImage = layoutLayersToOneImage(images, colCount, margin)\n",
    "        imshow(matrixImage);\n",
    "    #     imshow(images[0])\n",
    "        plt.show()\n",
    "\n",
    "if 0:\n",
    " for n, val in enumerate(tfDataset.take(0)):\n",
    "  # ??val\n",
    "  image = val[0][0].numpy()\n",
    "  # classInd = val[1].numpy()\n",
    "  # className = controlObj.imageDataset.getClassNameByInd(classInd) #.decode('ascii')\n",
    "  classVec = val[1][0].numpy()\n",
    "  print(image.shape)\n",
    "  ax = plt.subplot(4,4,n+1)\n",
    "  plt.text(1.1, 0.5, str(classVec),  \n",
    "          transform = ax.transAxes)\n",
    "  plt.imshow(image /255.0)\n",
    "#   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if 1:\n",
    "    imList = enumerate(tfDataset.take(6))\n",
    "    #??imList\n",
    "#     print(imList[0].shape())\n",
    "else:\n",
    "    v = next(tfDataset)\n",
    "    imList = [im for im in v[0][:6]]\n",
    "matrixImage = layoutLayersToOneImage(np.stack(imList), 3, margin)\n",
    "imshow(matrixImage);\n",
    "print(v[1][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.034 ( 64885.00) 160\n",
      "11.036 (  2346.00) Cur control object epoch 0, wrapper - 26\n",
      "11.137 (101026.00) Learning rate switched to 0.000090\n",
      "Epoch 27/27\n",
      " - 55s - loss: 0.0404 - accuracy: 0.0573 - val_loss: 0.0400 - val_accuracy: 0.0547\n",
      "113.642 (102505380.00) acts: 6.02 MBs, images: 3174 object(s), 28 + 0 in LRU lists, 551.56 MBs\n",
      "113.760 (117760.00) Epoch 27: loss 0.04043, acc 0.0573, last 1 epochs: 58.6875 s\n",
      "Epoch 28/28\n",
      " - 48s - loss: 0.0404 - accuracy: 0.0437 - val_loss: 0.0399 - val_accuracy: 0.0625\n",
      "200.714 (86953912.00) acts: 6.02 MBs, images: 5557 object(s), 829 + 0 in LRU lists, 972.89 MBs\n",
      "200.840 (126368.00) Epoch 28: loss 0.04036, acc 0.0437, last 1 epochs: 48.4702 s\n",
      "Epoch 29/29\n",
      " - 48s - loss: 0.0405 - accuracy: 0.0469 - val_loss: 0.0398 - val_accuracy: 0.0938\n",
      "284.483 (83642307.00) acts: 6.02 MBs, images: 7432 object(s), 1888 + 0 in LRU lists, 1307.46 MBs\n",
      "284.599 (116401.00) Epoch 29: loss 0.04045, acc 0.0469, last 1 epochs: 48.3976 s\n",
      "Epoch 30/30\n",
      " - 48s - loss: 0.0404 - accuracy: 0.0490 - val_loss: 0.0399 - val_accuracy: 0.0938\n",
      "365.583 (80983818.00) acts: 6.02 MBs, images: 8817 object(s), 3147 + 0 in LRU lists, 1557.53 MBs\n",
      "365.695 (111791.00) Epoch 30: loss 0.04039, acc 0.0490, last 1 epochs: 48.2431 s\n",
      "Epoch 31/31\n",
      " - 97s - loss: 0.0402 - accuracy: 0.0524 - val_loss: 0.0398 - val_accuracy: 0.0906\n",
      "504.230 (138535750.00) acts: 6.02 MBs, images: 10495 object(s), 4755 + 0 in LRU lists, 1863.74 MBs\n",
      "504.342 (111244.00) Epoch 31: loss 0.04022, acc 0.0524, last 1 epochs: 96.9262 s\n",
      "Epoch 32/32\n",
      " - 192s - loss: 0.0402 - accuracy: 0.0426 - val_loss: 0.0397 - val_accuracy: 0.0781\n",
      "754.998 (250656293.00) acts: 6.02 MBs, images: 12340 object(s), 3543 + 5120 in LRU lists, 2204.63 MBs\n",
      "755.153 (154688.00) Epoch 32: loss 0.04019, acc 0.0426, last 1 epochs: 192.2194 s\n",
      "Epoch 33/33\n",
      " - 385s - loss: 0.0401 - accuracy: 0.0560 - val_loss: 0.0400 - val_accuracy: 0.1164\n",
      "1229.090 (473937487.00) acts: 6.02 MBs, images: 14140 object(s), 1305 + 5120 in LRU lists, 2538.00 MBs\n",
      "1229.193 (102522.00) Epoch 33: loss 0.04006, acc 0.0560, last 1 epochs: 384.9080 s\n",
      "Epoch 34/34\n",
      " - 479s - loss: 0.0399 - accuracy: 0.0725 - val_loss: 0.0398 - val_accuracy: 0.1346\n",
      "1806.491 (577298219.00) acts: 6.02 MBs, images: 14982 object(s), 2377 + 5120 in LRU lists, 2693.35 MBs\n",
      "1806.597 (106102.00) Epoch 34: loss 0.03993, acc 0.0725, last 1 epochs: 479.4457 s\n",
      "Epoch 35/35\n",
      " - 477s - loss: 0.0397 - accuracy: 0.0909 - val_loss: 0.0388 - val_accuracy: 0.1508\n",
      "2376.423 (569826059.00) acts: 6.02 MBs, images: 15207 object(s), 3833 + 5120 in LRU lists, 2734.86 MBs\n",
      "2376.534 (111377.00) Epoch 35: loss 0.03966, acc 0.0909, last 1 epochs: 477.5235 s\n",
      "Epoch 36/36\n",
      " - 479s - loss: 0.0394 - accuracy: 0.1099 - val_loss: 0.0386 - val_accuracy: 0.1394\n",
      "2946.759 (570224731.00) acts: 6.02 MBs, images: 15288 object(s), 397 + 5120 in LRU lists, 2749.76 MBs\n",
      "2946.862 (102341.00) Epoch 36: loss 0.03945, acc 0.1099, last 1 epochs: 479.3994 s\n",
      "Epoch 37/37\n",
      " - 479s - loss: 0.0392 - accuracy: 0.1242 - val_loss: 0.0392 - val_accuracy: 0.1791\n",
      "3518.530 (571668918.00) Epoch 37: loss 0.03917, acc 0.1242, last 1 epochs: 479.5025 s\n",
      "Epoch 38/38\n",
      " - 478s - loss: 0.0389 - accuracy: 0.1407 - val_loss: 0.0382 - val_accuracy: 0.1629\n",
      "4087.524 (568993164.00) Epoch 38: loss 0.03893, acc 0.1407, last 1 epochs: 478.2970 s\n",
      "Epoch 39/39\n",
      " - 479s - loss: 0.0389 - accuracy: 0.1463 - val_loss: 0.0361 - val_accuracy: 0.1839\n",
      "4658.401 (570877348.00) Epoch 39: loss 0.03888, acc 0.1463, last 1 epochs: 479.3225 s\n",
      "Epoch 40/40\n",
      " - 479s - loss: 0.0385 - accuracy: 0.1554 - val_loss: 0.0384 - val_accuracy: 0.2079\n",
      "5229.279 (570877777.00) Epoch 40: loss 0.03847, acc 0.1554, last 1 epochs: 479.3185 s\n",
      "Epoch 41/41\n",
      " - 479s - loss: 0.0384 - accuracy: 0.1665 - val_loss: 0.0364 - val_accuracy: 0.1875\n",
      "5800.742 (571463416.00) Epoch 41: loss 0.03837, acc 0.1665, last 1 epochs: 479.5455 s\n",
      "Epoch 42/42\n",
      " - 478s - loss: 0.0382 - accuracy: 0.1685 - val_loss: 0.0407 - val_accuracy: 0.1929\n",
      "6369.584 (568841984.00) Epoch 42: loss 0.03823, acc 0.1685, last 1 epochs: 478.1262 s\n",
      "Epoch 43/43\n",
      " - 480s - loss: 0.0379 - accuracy: 0.1806 - val_loss: 0.0358 - val_accuracy: 0.2236\n",
      "6942.033 (572448960.00) Epoch 43: loss 0.03791, acc 0.1806, last 1 epochs: 480.3946 s\n",
      "Epoch 44/44\n",
      " - 478s - loss: 0.0378 - accuracy: 0.1833 - val_loss: 0.0377 - val_accuracy: 0.1947\n",
      "7512.319 (570286049.00) Epoch 44: loss 0.03779, acc 0.1833, last 1 epochs: 478.4675 s\n",
      "Epoch 45/45\n",
      " - 478s - loss: 0.0376 - accuracy: 0.1847 - val_loss: 0.0373 - val_accuracy: 0.2163\n",
      "8082.126 (569806478.00) Epoch 45: loss 0.03765, acc 0.1847, last 1 epochs: 478.4727 s\n",
      "Epoch 46/46\n",
      " - 479s - loss: 0.0376 - accuracy: 0.1879 - val_loss: 0.0377 - val_accuracy: 0.2115\n",
      "8650.588 (568462607.00) acts: 6.02 MBs, images: 15319 object(s), 3130 + 5120 in LRU lists, 2755.42 MBs\n",
      "8650.691 (103136.00) Epoch 46: loss 0.03756, acc 0.1879, last 1 epochs: 479.3323 s\n",
      "Epoch 47/47\n",
      " - 479s - loss: 0.0375 - accuracy: 0.1916 - val_loss: 0.0390 - val_accuracy: 0.2181\n",
      "9220.118 (569426783.00) Epoch 47: loss 0.03755, acc 0.1916, last 1 epochs: 479.4129 s\n",
      "Epoch 48/48\n",
      " - 480s - loss: 0.0374 - accuracy: 0.1990 - val_loss: 0.0364 - val_accuracy: 0.2500\n",
      "9792.493 (572374510.00) Epoch 48: loss 0.03738, acc 0.1990, last 1 epochs: 479.8092 s\n",
      "Epoch 49/49\n",
      " - 478s - loss: 0.0373 - accuracy: 0.2108 - val_loss: 0.0365 - val_accuracy: 0.2338\n",
      "10362.848 (570355172.00) Epoch 49: loss 0.03730, acc 0.2108, last 1 epochs: 478.1538 s\n",
      "Epoch 50/50\n",
      " - 480s - loss: 0.0371 - accuracy: 0.2093 - val_loss: 0.0384 - val_accuracy: 0.2452\n",
      "10933.215 (570367427.00) Epoch 50: loss 0.03711, acc 0.2093, last 1 epochs: 479.7923 s\n",
      "Epoch 51/51\n",
      " - 478s - loss: 0.0370 - accuracy: 0.2109 - val_loss: 0.0351 - val_accuracy: 0.2536\n",
      "11501.869 (568653411.00) Epoch 51: loss 0.03699, acc 0.2109, last 1 epochs: 478.4285 s\n",
      "Epoch 52/52\n",
      " - 477s - loss: 0.0369 - accuracy: 0.2145 - val_loss: 0.0355 - val_accuracy: 0.2524\n",
      "12070.404 (568535104.00) Epoch 52: loss 0.03690, acc 0.2145, last 1 epochs: 477.3612 s\n",
      "Epoch 53/53\n",
      " - 479s - loss: 0.0367 - accuracy: 0.2174 - val_loss: 0.0373 - val_accuracy: 0.2596\n",
      "12640.111 (569707536.00) Epoch 53: loss 0.03666, acc 0.2174, last 1 epochs: 478.7214 s\n",
      "Epoch 54/54\n",
      " - 478s - loss: 0.0366 - accuracy: 0.2253 - val_loss: 0.0377 - val_accuracy: 0.2488\n",
      "13209.071 (568959410.00) Epoch 54: loss 0.03662, acc 0.2253, last 1 epochs: 478.2871 s\n",
      "Epoch 55/55\n",
      " - 477s - loss: 0.0365 - accuracy: 0.2248 - val_loss: 0.0340 - val_accuracy: 0.2879\n",
      "13777.057 (567986465.00) Epoch 55: loss 0.03653, acc 0.2248, last 1 epochs: 477.1534 s\n",
      "Epoch 56/56\n",
      " - 478s - loss: 0.0362 - accuracy: 0.2328 - val_loss: 0.0305 - val_accuracy: 0.2608\n",
      "14346.307 (569249893.00) acts: 6.02 MBs, images: 15319 object(s), 893 + 5120 in LRU lists, 2755.42 MBs\n",
      "14346.436 (128974.00) Epoch 56: loss 0.03623, acc 0.2328, last 1 epochs: 478.1817 s\n",
      "Epoch 57/57\n",
      " - 477s - loss: 0.0363 - accuracy: 0.2290 - val_loss: 0.0358 - val_accuracy: 0.2566\n",
      "14914.178 (567741671.00) Epoch 57: loss 0.03631, acc 0.2290, last 1 epochs: 477.4585 s\n",
      "Epoch 58/58\n",
      " - 478s - loss: 0.0362 - accuracy: 0.2382 - val_loss: 0.0323 - val_accuracy: 0.2806\n",
      "15481.571 (567393044.00) Epoch 58: loss 0.03617, acc 0.2382, last 1 epochs: 477.9639 s\n",
      "Epoch 59/59\n",
      " - 478s - loss: 0.0361 - accuracy: 0.2444 - val_loss: 0.0361 - val_accuracy: 0.2740\n",
      "16051.438 (569866774.00) Epoch 59: loss 0.03607, acc 0.2444, last 1 epochs: 477.8976 s\n",
      "Epoch 60/60\n",
      " - 478s - loss: 0.0360 - accuracy: 0.2467 - val_loss: 0.0350 - val_accuracy: 0.2692\n",
      "16620.388 (568950564.00) Epoch 60: loss 0.03602, acc 0.2467, last 1 epochs: 477.5784 s\n",
      "Epoch 61/61\n",
      " - 477s - loss: 0.0360 - accuracy: 0.2451 - val_loss: 0.0363 - val_accuracy: 0.2662\n",
      "17188.319 (567930440.00) Epoch 61: loss 0.03604, acc 0.2451, last 1 epochs: 477.5330 s\n",
      "Epoch 62/62\n",
      " - 478s - loss: 0.0358 - accuracy: 0.2503 - val_loss: 0.0368 - val_accuracy: 0.3065\n",
      "17757.093 (568774072.00) Epoch 62: loss 0.03576, acc 0.2503, last 1 epochs: 477.6594 s\n",
      "Epoch 63/63\n",
      " - 477s - loss: 0.0358 - accuracy: 0.2489 - val_loss: 0.0343 - val_accuracy: 0.2957\n",
      "18323.672 (566579716.00) Epoch 63: loss 0.03577, acc 0.2489, last 1 epochs: 476.9368 s\n",
      "Epoch 64/64\n",
      " - 478s - loss: 0.0356 - accuracy: 0.2585 - val_loss: 0.0353 - val_accuracy: 0.3113\n",
      "18891.886 (568213537.00) Epoch 64: loss 0.03560, acc 0.2585, last 1 epochs: 477.7724 s\n",
      "Epoch 65/65\n",
      " - 478s - loss: 0.0354 - accuracy: 0.2621 - val_loss: 0.0340 - val_accuracy: 0.3101\n",
      "19460.461 (568575117.00) Epoch 65: loss 0.03543, acc 0.2621, last 1 epochs: 477.7251 s\n",
      "Epoch 66/66\n",
      " - 477s - loss: 0.0356 - accuracy: 0.2545 - val_loss: 0.0367 - val_accuracy: 0.3017\n",
      "20028.200 (567738584.00) acts: 6.02 MBs, images: 15319 object(s), 3778 + 5120 in LRU lists, 2755.42 MBs\n",
      "20028.301 (101300.00) Epoch 66: loss 0.03562, acc 0.2545, last 1 epochs: 477.4654 s\n",
      "Epoch 67/67\n",
      " - 480s - loss: 0.0353 - accuracy: 0.2605 - val_loss: 0.0355 - val_accuracy: 0.2993\n",
      "20597.972 (569671020.00) Epoch 67: loss 0.03533, acc 0.2605, last 1 epochs: 479.6206 s\n",
      "Epoch 68/68\n",
      " - 477s - loss: 0.0353 - accuracy: 0.2648 - val_loss: 0.0343 - val_accuracy: 0.3233\n",
      "21165.432 (567460000.00) Epoch 68: loss 0.03533, acc 0.2648, last 1 epochs: 477.2118 s\n",
      "Epoch 69/69\n",
      " - 478s - loss: 0.0352 - accuracy: 0.2686 - val_loss: 0.0342 - val_accuracy: 0.3161\n",
      "21734.824 (569391808.00) Epoch 69: loss 0.03524, acc 0.2686, last 1 epochs: 478.2664 s\n",
      "Epoch 70/70\n",
      " - 478s - loss: 0.0349 - accuracy: 0.2789 - val_loss: 0.0334 - val_accuracy: 0.3413\n",
      "22301.845 (567021614.00) Epoch 70: loss 0.03491, acc 0.2789, last 1 epochs: 477.8919 s\n",
      "Epoch 71/71\n",
      " - 478s - loss: 0.0349 - accuracy: 0.2758 - val_loss: 0.0337 - val_accuracy: 0.3425\n",
      "22871.317 (569471941.00) Epoch 71: loss 0.03492, acc 0.2758, last 1 epochs: 478.1524 s\n",
      "Epoch 72/72\n",
      " - 478s - loss: 0.0349 - accuracy: 0.2802 - val_loss: 0.0330 - val_accuracy: 0.3492\n",
      "23440.737 (569419900.00) Epoch 72: loss 0.03486, acc 0.2802, last 1 epochs: 477.7777 s\n",
      "Epoch 73/73\n",
      " - 477s - loss: 0.0350 - accuracy: 0.2746 - val_loss: 0.0334 - val_accuracy: 0.3149\n",
      "24008.304 (567567078.00) Epoch 73: loss 0.03500, acc 0.2746, last 1 epochs: 476.7012 s\n",
      "Epoch 74/74\n",
      " - 478s - loss: 0.0348 - accuracy: 0.2787 - val_loss: 0.0336 - val_accuracy: 0.3606\n",
      "24577.114 (568809525.00) Epoch 74: loss 0.03480, acc 0.2787, last 1 epochs: 477.9579 s\n",
      "Epoch 75/75\n",
      " - 478s - loss: 0.0347 - accuracy: 0.2886 - val_loss: 0.0325 - val_accuracy: 0.3528\n",
      "25144.783 (567669164.00) Epoch 75: loss 0.03469, acc 0.2886, last 1 epochs: 477.6779 s\n",
      "Epoch 76/76\n",
      " - 478s - loss: 0.0345 - accuracy: 0.2830 - val_loss: 0.0383 - val_accuracy: 0.3456\n",
      "25713.526 (568743451.00) acts: 6.02 MBs, images: 15319 object(s), 1461 + 5120 in LRU lists, 2755.42 MBs\n",
      "25713.629 (102536.00) Epoch 76: loss 0.03454, acc 0.2830, last 1 epochs: 478.2532 s\n",
      "Epoch 77/77\n",
      " - 478s - loss: 0.0345 - accuracy: 0.2859 - val_loss: 0.0321 - val_accuracy: 0.3498\n",
      "26282.569 (568939994.00) Epoch 77: loss 0.03446, acc 0.2859, last 1 epochs: 478.1250 s\n",
      "Epoch 78/78\n",
      " - 477s - loss: 0.0341 - accuracy: 0.2935 - val_loss: 0.0333 - val_accuracy: 0.3371\n",
      "26851.040 (568471457.00) Epoch 78: loss 0.03412, acc 0.2935, last 1 epochs: 477.3563 s\n",
      "Epoch 79/79\n",
      " - 477s - loss: 0.0343 - accuracy: 0.2938 - val_loss: 0.0295 - val_accuracy: 0.3720\n",
      "27420.219 (569178555.00) Epoch 79: loss 0.03430, acc 0.2938, last 1 epochs: 477.2665 s\n",
      "Epoch 80/80\n",
      " - 478s - loss: 0.0344 - accuracy: 0.2853 - val_loss: 0.0314 - val_accuracy: 0.3546\n",
      "27989.824 (569605249.00) Epoch 80: loss 0.03442, acc 0.2853, last 1 epochs: 478.0902 s\n",
      "Epoch 81/81\n",
      " - 479s - loss: 0.0342 - accuracy: 0.2975 - val_loss: 0.0291 - val_accuracy: 0.3624\n",
      "28559.744 (569919612.00) Epoch 81: loss 0.03418, acc 0.2975, last 1 epochs: 478.6345 s\n",
      "Epoch 82/82\n",
      " - 478s - loss: 0.0343 - accuracy: 0.3000 - val_loss: 0.0327 - val_accuracy: 0.3582\n",
      "29128.865 (569121202.00) Epoch 82: loss 0.03431, acc 0.3000, last 1 epochs: 478.1188 s\n",
      "Epoch 83/83\n",
      " - 478s - loss: 0.0342 - accuracy: 0.3012 - val_loss: 0.0295 - val_accuracy: 0.3588\n",
      "29697.663 (568797679.00) Epoch 83: loss 0.03416, acc 0.3012, last 1 epochs: 478.1124 s\n",
      "Epoch 84/84\n",
      " - 478s - loss: 0.0341 - accuracy: 0.2976 - val_loss: 0.0329 - val_accuracy: 0.3257\n",
      "30267.636 (569973504.00) Epoch 84: loss 0.03407, acc 0.2976, last 1 epochs: 478.2718 s\n",
      "Epoch 85/85\n",
      " - 479s - loss: 0.0340 - accuracy: 0.3039 - val_loss: 0.0298 - val_accuracy: 0.4075\n",
      "30837.790 (570154101.00) Epoch 85: loss 0.03404, acc 0.3039, last 1 epochs: 478.6262 s\n",
      "Epoch 86/86\n",
      " - 476s - loss: 0.0339 - accuracy: 0.3096 - val_loss: 0.0321 - val_accuracy: 0.3660\n",
      "31404.338 (566548085.00) acts: 6.02 MBs, images: 15319 object(s), 4480 + 5120 in LRU lists, 2755.42 MBs\n",
      "31404.441 (102999.00) Epoch 86: loss 0.03387, acc 0.3096, last 1 epochs: 476.4648 s\n",
      "Epoch 87/87\n",
      " - 477s - loss: 0.0338 - accuracy: 0.3119 - val_loss: 0.0318 - val_accuracy: 0.3690\n",
      "31972.455 (568013407.00) Epoch 87: loss 0.03375, acc 0.3119, last 1 epochs: 477.3374 s\n",
      "Epoch 88/88\n",
      " - 477s - loss: 0.0336 - accuracy: 0.3116 - val_loss: 0.0300 - val_accuracy: 0.3666\n",
      "32540.342 (567887096.00) Epoch 88: loss 0.03361, acc 0.3116, last 1 epochs: 477.5194 s\n",
      "Epoch 89/89\n",
      " - 478s - loss: 0.0338 - accuracy: 0.3118 - val_loss: 0.0321 - val_accuracy: 0.3660\n",
      "33108.116 (567773689.00) Epoch 89: loss 0.03381, acc 0.3118, last 1 epochs: 478.2112 s\n",
      "Epoch 90/90\n",
      " - 476s - loss: 0.0337 - accuracy: 0.3149 - val_loss: 0.0292 - val_accuracy: 0.3738\n",
      "33675.025 (566909777.00) Epoch 90: loss 0.03371, acc 0.3149, last 1 epochs: 476.0389 s\n",
      "Epoch 91/91\n",
      " - 477s - loss: 0.0332 - accuracy: 0.3256 - val_loss: 0.0359 - val_accuracy: 0.4207\n",
      "34240.944 (565918484.00) Epoch 91: loss 0.03318, acc 0.3256, last 1 epochs: 477.3658 s\n",
      "Epoch 92/92\n",
      " - 477s - loss: 0.0337 - accuracy: 0.3184 - val_loss: 0.0284 - val_accuracy: 0.3762\n",
      "34809.059 (568115215.00) Epoch 92: loss 0.03375, acc 0.3184, last 1 epochs: 477.4020 s\n",
      "Epoch 93/93\n",
      " - 477s - loss: 0.0333 - accuracy: 0.3234 - val_loss: 0.0348 - val_accuracy: 0.3678\n",
      "35376.908 (567849145.00) Epoch 93: loss 0.03328, acc 0.3234, last 1 epochs: 477.2346 s\n",
      "Epoch 94/94\n",
      " - 478s - loss: 0.0334 - accuracy: 0.3219 - val_loss: 0.0305 - val_accuracy: 0.3738\n",
      "35946.635 (569726696.00) Epoch 94: loss 0.03340, acc 0.3219, last 1 epochs: 478.3101 s\n",
      "Epoch 95/95\n",
      " - 478s - loss: 0.0331 - accuracy: 0.3300 - val_loss: 0.0327 - val_accuracy: 0.3768\n",
      "36515.926 (569291482.00) Epoch 95: loss 0.03311, acc 0.3300, last 1 epochs: 477.9171 s\n",
      "Epoch 96/96\n",
      " - 478s - loss: 0.0330 - accuracy: 0.3323 - val_loss: 0.0322 - val_accuracy: 0.3906\n",
      "37084.538 (568611269.00) acts: 6.02 MBs, images: 15319 object(s), 2120 + 5120 in LRU lists, 2755.42 MBs\n",
      "37084.665 (127616.00) Epoch 96: loss 0.03296, acc 0.3323, last 1 epochs: 478.5153 s\n",
      "Epoch 97/97\n",
      " - 477s - loss: 0.0328 - accuracy: 0.3372 - val_loss: 0.0333 - val_accuracy: 0.4002\n",
      "37652.506 (567840821.00) Epoch 97: loss 0.03283, acc 0.3372, last 1 epochs: 477.1153 s\n",
      "Epoch 98/98\n",
      " - 479s - loss: 0.0331 - accuracy: 0.3280 - val_loss: 0.0333 - val_accuracy: 0.4050\n",
      "38221.338 (568832010.00) Epoch 98: loss 0.03308, acc 0.3280, last 1 epochs: 478.7484 s\n",
      "Epoch 99/99\n",
      " - 479s - loss: 0.0328 - accuracy: 0.3416 - val_loss: 0.0296 - val_accuracy: 0.3858\n",
      "38790.570 (569231998.00) Epoch 99: loss 0.03277, acc 0.3416, last 1 epochs: 478.8844 s\n",
      "Epoch 100/100\n",
      " - 477s - loss: 0.0329 - accuracy: 0.3300 - val_loss: 0.0316 - val_accuracy: 0.3816\n",
      "39357.590 (567020236.00) Epoch 100: loss 0.03289, acc 0.3300, last 1 epochs: 477.3045 s\n",
      "Epoch 101/101\n",
      " - 478s - loss: 0.0328 - accuracy: 0.3330 - val_loss: 0.0308 - val_accuracy: 0.4273\n",
      "39926.606 (569015507.00) Epoch 101: loss 0.03285, acc 0.3330, last 1 epochs: 478.2184 s\n",
      "Epoch 102/102\n",
      " - 479s - loss: 0.0329 - accuracy: 0.3301 - val_loss: 0.0315 - val_accuracy: 0.4002\n",
      "40496.987 (570381205.00) Epoch 102: loss 0.03293, acc 0.3301, last 1 epochs: 478.6741 s\n",
      "Epoch 103/103\n",
      " - 477s - loss: 0.0326 - accuracy: 0.3421 - val_loss: 0.0312 - val_accuracy: 0.4219\n",
      "41065.201 (568214040.00) Epoch 103: loss 0.03256, acc 0.3421, last 1 epochs: 477.5105 s\n",
      "Epoch 104/104\n",
      " - 477s - loss: 0.0325 - accuracy: 0.3462 - val_loss: 0.0299 - val_accuracy: 0.4032\n",
      "41633.907 (568706250.00) Epoch 104: loss 0.03250, acc 0.3462, last 1 epochs: 477.4251 s\n",
      "Epoch 105/105\n",
      " - 479s - loss: 0.0324 - accuracy: 0.3428 - val_loss: 0.0311 - val_accuracy: 0.4062\n",
      "42203.559 (569651872.00) Epoch 105: loss 0.03243, acc 0.3428, last 1 epochs: 479.4126 s\n",
      "Epoch 106/106\n",
      " - 478s - loss: 0.0325 - accuracy: 0.3471 - val_loss: 0.0298 - val_accuracy: 0.4105\n",
      "42772.678 (569119107.00) acts: 6.02 MBs, images: 15319 object(s), 4751 + 5120 in LRU lists, 2755.42 MBs\n",
      "42772.793 (114299.00) Epoch 106: loss 0.03247, acc 0.3471, last 1 epochs: 478.3569 s\n",
      "Epoch 107/107\n",
      " - 479s - loss: 0.0323 - accuracy: 0.3492 - val_loss: 0.0307 - val_accuracy: 0.4207\n",
      "43340.501 (567708089.00) Epoch 107: loss 0.03225, acc 0.3492, last 1 epochs: 478.6527 s\n",
      "Epoch 108/108\n",
      " - 479s - loss: 0.0324 - accuracy: 0.3495 - val_loss: 0.0291 - val_accuracy: 0.4069\n",
      "43909.067 (568566202.00) Epoch 108: loss 0.03238, acc 0.3495, last 1 epochs: 479.0495 s\n",
      "Epoch 109/109\n",
      " - 478s - loss: 0.0322 - accuracy: 0.3563 - val_loss: 0.0317 - val_accuracy: 0.4171\n",
      "44478.571 (569504615.00) Epoch 109: loss 0.03222, acc 0.3563, last 1 epochs: 478.1154 s\n",
      "Epoch 110/110\n",
      " - 478s - loss: 0.0321 - accuracy: 0.3574 - val_loss: 0.0273 - val_accuracy: 0.4333\n",
      "45046.590 (568018177.00) Epoch 110: loss 0.03213, acc 0.3574, last 1 epochs: 477.6586 s\n",
      "Epoch 111/111\n",
      " - 479s - loss: 0.0322 - accuracy: 0.3490 - val_loss: 0.0281 - val_accuracy: 0.4435\n",
      "45616.731 (570141374.00) Epoch 111: loss 0.03218, acc 0.3490, last 1 epochs: 479.3584 s\n",
      "Epoch 112/112\n",
      " - 479s - loss: 0.0318 - accuracy: 0.3561 - val_loss: 0.0306 - val_accuracy: 0.4069\n",
      "46186.127 (569395809.00) Epoch 112: loss 0.03180, acc 0.3561, last 1 epochs: 478.7044 s\n",
      "Epoch 113/113\n",
      " - 477s - loss: 0.0319 - accuracy: 0.3572 - val_loss: 0.0310 - val_accuracy: 0.3972\n",
      "46753.462 (567334677.00) Epoch 113: loss 0.03194, acc 0.3572, last 1 epochs: 477.4898 s\n",
      "Epoch 114/114\n",
      " - 477s - loss: 0.0317 - accuracy: 0.3628 - val_loss: 0.0261 - val_accuracy: 0.4501\n",
      "47321.548 (568086615.00) Epoch 114: loss 0.03167, acc 0.3628, last 1 epochs: 477.3659 s\n",
      "Epoch 115/115\n",
      " - 478s - loss: 0.0320 - accuracy: 0.3529 - val_loss: 0.0319 - val_accuracy: 0.4201\n",
      "47888.895 (567346428.00) Epoch 115: loss 0.03200, acc 0.3529, last 1 epochs: 478.1879 s\n",
      "Epoch 116/116\n",
      " - 477s - loss: 0.0317 - accuracy: 0.3695 - val_loss: 0.0263 - val_accuracy: 0.4585\n",
      "48458.224 (569329598.00) acts: 6.02 MBs, images: 15319 object(s), 2998 + 5120 in LRU lists, 2755.42 MBs\n",
      "48458.328 (104010.00) Epoch 116: loss 0.03167, acc 0.3695, last 1 epochs: 477.4820 s\n",
      "Epoch 117/117\n",
      " - 478s - loss: 0.0319 - accuracy: 0.3590 - val_loss: 0.0281 - val_accuracy: 0.4465\n",
      "49026.267 (567938652.00) Epoch 117: loss 0.03188, acc 0.3590, last 1 epochs: 478.0320 s\n",
      "Epoch 118/118\n",
      " - 479s - loss: 0.0318 - accuracy: 0.3615 - val_loss: 0.0286 - val_accuracy: 0.4189\n",
      "49594.571 (568304567.00) Epoch 118: loss 0.03181, acc 0.3615, last 1 epochs: 478.5980 s\n",
      "Epoch 119/119\n",
      " - 479s - loss: 0.0319 - accuracy: 0.3571 - val_loss: 0.0316 - val_accuracy: 0.4351\n",
      "50164.852 (570280200.00) Epoch 119: loss 0.03186, acc 0.3571, last 1 epochs: 478.6178 s\n",
      "Epoch 120/120\n",
      " - 478s - loss: 0.0315 - accuracy: 0.3660 - val_loss: 0.0265 - val_accuracy: 0.4411\n",
      "50732.949 (568097749.00) Epoch 120: loss 0.03151, acc 0.3660, last 1 epochs: 477.9490 s\n",
      "Epoch 121/121\n",
      " - 479s - loss: 0.0311 - accuracy: 0.3769 - val_loss: 0.0272 - val_accuracy: 0.4351\n",
      "51302.598 (569648224.00) Epoch 121: loss 0.03108, acc 0.3769, last 1 epochs: 478.5618 s\n",
      "Epoch 122/122\n",
      " - 479s - loss: 0.0314 - accuracy: 0.3731 - val_loss: 0.0303 - val_accuracy: 0.4453\n",
      "51871.358 (568760694.00) Epoch 122: loss 0.03139, acc 0.3731, last 1 epochs: 478.6156 s\n",
      "Epoch 123/123\n",
      " - 478s - loss: 0.0314 - accuracy: 0.3684 - val_loss: 0.0329 - val_accuracy: 0.4273\n",
      "52439.818 (568459553.00) Epoch 123: loss 0.03143, acc 0.3684, last 1 epochs: 478.4849 s\n",
      "Epoch 124/124\n",
      " - 478s - loss: 0.0311 - accuracy: 0.3836 - val_loss: 0.0304 - val_accuracy: 0.4213\n",
      "53007.595 (567777437.00) Epoch 124: loss 0.03108, acc 0.3836, last 1 epochs: 477.7675 s\n",
      "Epoch 125/125\n",
      " - 478s - loss: 0.0312 - accuracy: 0.3784 - val_loss: 0.0278 - val_accuracy: 0.4573\n",
      "53574.031 (566435972.00) Epoch 125: loss 0.03115, acc 0.3784, last 1 epochs: 477.5847 s\n",
      "Epoch 126/126\n",
      " - 478s - loss: 0.0312 - accuracy: 0.3769 - val_loss: 0.0268 - val_accuracy: 0.4291\n",
      "54143.237 (569205697.00) acts: 6.02 MBs, images: 15319 object(s), 503 + 5120 in LRU lists, 2755.42 MBs\n",
      "54143.338 (100932.00) Epoch 126: loss 0.03117, acc 0.3769, last 1 epochs: 477.7007 s\n",
      "Epoch 127/127\n",
      " - 478s - loss: 0.0314 - accuracy: 0.3736 - val_loss: 0.0234 - val_accuracy: 0.4405\n",
      "54712.270 (568932072.00) Epoch 127: loss 0.03140, acc 0.3736, last 1 epochs: 478.3730 s\n",
      "Epoch 128/128\n",
      " - 478s - loss: 0.0309 - accuracy: 0.3900 - val_loss: 0.0275 - val_accuracy: 0.4489\n",
      "55280.904 (568633676.00) Epoch 128: loss 0.03088, acc 0.3900, last 1 epochs: 477.9136 s\n",
      "Epoch 129/129\n",
      " - 478s - loss: 0.0310 - accuracy: 0.3820 - val_loss: 0.0250 - val_accuracy: 0.4333\n",
      "55848.761 (567857103.00) Epoch 129: loss 0.03104, acc 0.3820, last 1 epochs: 478.3548 s\n",
      "Epoch 130/130\n",
      " - 478s - loss: 0.0310 - accuracy: 0.3799 - val_loss: 0.0273 - val_accuracy: 0.4573\n",
      "56416.304 (567543696.00) Epoch 130: loss 0.03105, acc 0.3799, last 1 epochs: 478.0790 s\n",
      "Epoch 131/131\n",
      " - 478s - loss: 0.0306 - accuracy: 0.3895 - val_loss: 0.0257 - val_accuracy: 0.4525\n",
      "56986.145 (569840343.00) Epoch 131: loss 0.03056, acc 0.3895, last 1 epochs: 477.9189 s\n",
      "Epoch 132/132\n",
      " - 479s - loss: 0.0307 - accuracy: 0.3877 - val_loss: 0.0237 - val_accuracy: 0.4688\n",
      "57555.501 (569356074.00) Epoch 132: loss 0.03072, acc 0.3877, last 1 epochs: 478.6658 s\n",
      "Epoch 133/133\n",
      " - 477s - loss: 0.0305 - accuracy: 0.3958 - val_loss: 0.0299 - val_accuracy: 0.4471\n",
      "58123.778 (568277286.00) Epoch 133: loss 0.03052, acc 0.3958, last 1 epochs: 476.9786 s\n",
      "Epoch 134/134\n",
      " - 478s - loss: 0.0307 - accuracy: 0.3911 - val_loss: 0.0274 - val_accuracy: 0.4651\n",
      "58693.246 (569468310.00) Epoch 134: loss 0.03068, acc 0.3911, last 1 epochs: 478.1788 s\n",
      "Epoch 135/135\n",
      " - 477s - loss: 0.0306 - accuracy: 0.3990 - val_loss: 0.0291 - val_accuracy: 0.4609\n",
      "59260.693 (567446660.00) Epoch 135: loss 0.03057, acc 0.3990, last 1 epochs: 476.9660 s\n",
      "Epoch 136/136\n",
      " - 477s - loss: 0.0306 - accuracy: 0.3948 - val_loss: 0.0222 - val_accuracy: 0.4814\n",
      "59827.492 (566798542.00) acts: 6.02 MBs, images: 15319 object(s), 3298 + 5120 in LRU lists, 2755.42 MBs\n",
      "59827.619 (127514.00) Epoch 136: loss 0.03060, acc 0.3948, last 1 epochs: 476.6618 s\n",
      "Epoch 137/137\n"
     ]
    }
   ],
   "source": [
    "controlObj.netWrapper.imageCache.maxMemory = 4 << 30\n",
    "controlObj.learnRate = 9e-5\n",
    "print(controlObj.netWrapper.net.batchSize)\n",
    "controlObj.netWrapper.net.batchSize = 64\n",
    "# controlObj.netWrapper.setLearnRate(controlObj.netWrapper.getRecommendedLearnRate())\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_23'])\n",
    "# controlObj.netWrapper._initMainNet()\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_11', False)\n",
    "controlObj.onDoItersPressed(7000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', False)\n",
    "controlObj.onDoItersPressed(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(controlObj.netWrapper.getCacheStatusInfo(True))\n",
    "controlObj.learnRate = 5e-6\n",
    "\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.doubleLayerWeights(['conv_22'])\n",
    "# controlObj.onDoItersPressed(3000)\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_3', 'dense_2'])\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_13', False)\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', False)\n",
    "controlObj.onDoItersPressed(3000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_22', False)\n",
    "controlObj.onDoItersPressed(3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlObj.netWrapper.imageCache.maxMemory = 4 << 30\n",
    "# controlObj.netWrapper.net.batchSize = 48\n",
    "\n",
    "controlObj.learnRate = 1e-7\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_13', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_22', True)\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', False)\n",
    "controlObj.onDoItersPressed(10000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_3', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_1', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_23', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_4'])\n",
    "# controlObj.onDoItersPressed(20000)\n",
    "\n",
    "controlObj.learnRate = 1e-8\n",
    "controlObj.onDoItersPressed(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "for i in range(3):\n",
    "    imshow(activations[i],cmap='Greys_r')   # Displays only one\n",
    "#display(activations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImagesMatrix(data, col=2):\n",
    "    fig = figure( figsize=(600, 300))\n",
    "    number_of_files = len(data)\n",
    "    print(number_of_files)\n",
    "    row = number_of_files/col\n",
    "    if (number_of_files%col != 0):\n",
    "        row += 1\n",
    "    for i in range(number_of_files):\n",
    "        a=fig.add_subplot(row,col,i+1)\n",
    "        # image = imread(mypath+'/'+list_of_files[i])\n",
    "        axis('off')\n",
    "        print('Image %d drawn' % i)\n",
    "    # Very slow at the end\n",
    "        \n",
    "showImagesMatrix(activations[1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.permutation(600)[:4]:\n",
    "    count = count + 1\n",
    "    plt.subplot(1, sample_size, count)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image(filename=\"image/000644.jpg\", width=100, height=100)\n",
    "im.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![title](images/000644.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image          # Displaying of multiple images. To check\n",
    "from IPython.display import display\n",
    "x = Image(filename='1.png') \n",
    "y = Image(filename='2.png') \n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "with out:\n",
    "    display(widgets.IntSlider())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
