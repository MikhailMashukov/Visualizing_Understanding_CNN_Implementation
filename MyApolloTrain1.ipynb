{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyT9_3\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.getcwd()\n",
    "print(tf.__version__, tf.config.list_physical_devices('GPU'))\n",
    "# !pwd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "# %rm -r QtLogs\n",
    "\n",
    "# from ipyexperiments import *\n",
    "# exp2 = IPyExperimentsPytorch()\n",
    "# from VisQtMain import *\n",
    "from VisJupyterNotUtils import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "print(keras.backend.backend())\n",
    "print(keras.backend.floatx())\n",
    "# arr = numpy.array([1.0, 2.0], dtype='float16')\n",
    "# print(arr.dtype)\n",
    "# new_arr = K.cast_to_floatx(arr)\n",
    "# print(new_arr.dtype)\n",
    "# print(tf.keras.mixed_precision.experimental.get_policy())\n",
    "keras.backend.set_floatx('float64')\n",
    "keras.backend.set_epsilon(1e-10)\n",
    "# keras.backend.set_epsilon(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !df -h\n",
    "# !cat /proc/cpuinfo\n",
    "# !top \n",
    "\n",
    "# import psutil\n",
    "\n",
    "# p = psutil.Process()\n",
    "# print(p.cpu_affinity())\n",
    "# p.cpu_affinity(range(0, 32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mv QtLogs/18_1/ ./\n",
    "# %mv QtLogs/*389.h5 QtLogs/18_1\n",
    "# %mkdir -p QtLogs/16_5\n",
    "# %mv QtLogs/*.h5 QtLogs/16_5/\n",
    "# %mv  QtLogs/16_5/*335* QtLogs/\n",
    "%mkdir -p QtLogs/src\n",
    "%cp -f * QtLogs/src/\n",
    "%cp -r PyTorch QtLogs/src/\n",
    "# %ls QtLogs\n",
    "# !mv ~/Visual_Z2/VKI*.zip ~/Visual_Z2/Data/\n",
    "# !rm /root/Visual_Z2/QtLogs/src/VKI*.zip\n",
    "# !tar chvfz notebook.tar.gz ~/Visualiz_Zeiler/QtLogs/src/*\n",
    "# !tar chvfz 15_4.tar.gz --no-recursion ~/Visualiz_Zeiler/*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "@interact   # Doesn't work now\n",
    "def f(x=5):\n",
    "    return x\n",
    "# interact(f, x=10);\n",
    "\n",
    "imageNum = 8\n",
    "image = controlObj.imageDataset.getImage(imageNum, 'cropped')\n",
    "# imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    %pylab inline\n",
    "        \n",
    "    model = controlObj.netWrapper._getNet()\n",
    "#     print(model)\n",
    "    imgs, classes = controlObj.netWrapper.getTrainBatch()\n",
    "    for img in imgs[:30]:\n",
    "        img = img.numpy()\n",
    "        print('min', img.min(), ', max', img.max())\n",
    "        img = img.transpose((1, 2, 0))\n",
    "        img = img / 5 + 0.5\n",
    "        plt.imshow(img);\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%pylab inline   \n",
    "    # Putting this to the first cell doesn't work (images are not plotted)\n",
    "subset = controlObj.netWrapper.imageDataset.trainSubset\n",
    "print(subset.getImageCount(), subset.getClassCount())\n",
    "for imageNum in range(1, 30, 1):\n",
    "    img = subset.getImage(imageNum)\n",
    "    classLabel = subset.getImageLabel(imageNum)\n",
    "    if classLabel != 1:\n",
    "        continue\n",
    "    print(imageNum, img.shape, img.dtype, (img / 255.0).max(), \n",
    "          classLabel, subset.getClassNameLabel(classLabel))\n",
    "    print(subset.imagesFileNames[imageNum])\n",
    "    plt.imshow(img / 255.0 + 0.5);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochNum = -3\n",
    "print(controlObj.getSelectedEpochNum())\n",
    "layerName = 'conv_11'\n",
    "activations, drawMode, stdData = controlObj.getActivationsData(epochNum, imageNum, layerName)\n",
    "actImage = layoutLayersToOneImage(np.sqrt(activations), colCount, margin)\n",
    "print(activations.shape, actImage.shape)\n",
    "plt.imshow(actImage);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(0):\n",
    "    activations = controlObj.netWrapper.getImageActivations('dense_2', i, epochNum)\n",
    "    print(activations);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "  return image\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)\n",
    "def load_and_preprocess_image_with_label(path, label):\n",
    "  print(path)\n",
    "  image = tf.io.read_file(path)\n",
    "  print(image, label)\n",
    "  return preprocess_image(image), label\n",
    "\n",
    "all_image_paths = [\"ImageNetPart/American crow/1003355_8d39d66686.jpg\", \n",
    "                   \"ImageNetPart/barn owl/101715431_19d0b37108.jpg\"]\n",
    "labels = ['crow', 'owl']\n",
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=1)\n",
    "# for n, image in enumerate(load_image_ds.take(7)):\n",
    "#     print(image)\n",
    "    \n",
    "label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "# ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "# for n, v in enumerate(ds.take(7)):\n",
    "#     print(v)\n",
    "ds = ds.repeat()\n",
    "# ds = ds.map(load_and_preprocess_image_with_label, num_parallel_calls=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Internal dataset's check\n",
    "ds = controlObj.imageDataset.getTfDataset('train') \n",
    "print(ds)\n",
    "plt.figure(figsize=(8,8))\n",
    "for n, val in enumerate(ds.take(3)):\n",
    "#     ??val\n",
    "    print(val, val[0].numpy())\n",
    "    imageNum = val[0].numpy()\n",
    "    # classInd = val[1].numpy()\n",
    "    classInd = val[1].numpy()\n",
    "#     if imageNum % 1000 == 0:\n",
    "#         print(val)\n",
    "#     continue\n",
    "    className = controlObj.imageDataset.getClassNameLabel(classInd) #.decode('ascii')\n",
    "    ax = plt.subplot(4,4,n+1)\n",
    "    plt.text(1.1, 0.5, '%s (%s)' % (className, str(classInd)),  \n",
    "          transform = ax.transAxes)\n",
    "#     image = controlObj.imageDataset.getImage(imageNum, 'cropped', 'test')\n",
    "    image = controlObj.imageDataset.getImage(imageNum, 'net', 'train')\n",
    "    print(image.shape, image.min(), image.max())\n",
    "    plt.imshow(image / 255.0 + 0.5)\n",
    "    #   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Final (batched) datasets' check\n",
    "controlObj.netWrapper._getNet()\n",
    "controlObj.netWrapper.net.batchSize = 16\n",
    "trainImageNums = np.arange(1, controlObj.imageDataset.getImageCount('train') + 1)\n",
    "testImageNums = np.arange(1, controlObj.imageDataset.getImageCount('test') + 1)\n",
    "tfTrainDataset, tfTestDataset = controlObj.netWrapper.net._getTfDatasets(\n",
    "                trainImageNums, testImageNums, 1000)\n",
    "# tfDataset = tf.compat.v1.data.make_one_shot_iterator(tfDataset)\n",
    "# ??tfDataset\n",
    "\n",
    "print(controlObj.imageDataset.getImageCount('train'))\n",
    "# for classInd in range(980, 1000):\n",
    "#     print(classInd, controlObj.imageDataset.getClassNameLabel(classInd))\n",
    "if 0:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for n, val in enumerate(tfTrainDataset.take(3)):\n",
    "#         print(controlObj.netWrapper.getCacheStatusInfo(True))\n",
    "        images = val[0].numpy()\n",
    "    #     ??images\n",
    "#         print(images.shape)\n",
    "        matrixImage = layoutLayersToOneImage(images, colCount, margin)\n",
    "#         imshow(matrixImage);\n",
    "    #     imshow(images[0])\n",
    "#         plt.show()\n",
    "\n",
    "        labels = val[1].numpy()\n",
    "        for imgInd, label in enumerate(labels):\n",
    "            classInd = np.argmax(label)\n",
    "            if 1: # classInd == 100:\n",
    "                print(classInd, label[classInd], controlObj.imageDataset.getClassNameLabel(classInd),\n",
    "                     images[imgInd].min(), images[imgInd].max())\n",
    "                imshow(images[imgInd] + [123, 116, 103])\n",
    "                plt.show()\n",
    "            \n",
    "\n",
    "if 0:\n",
    " for n, val in enumerate(tfDataset.take(0)):\n",
    "  # ??val\n",
    "  image = val[0][0].numpy()\n",
    "  # classInd = val[1].numpy()\n",
    "  # className = controlObj.imageDataset.getClassNameByInd(classInd) #.decode('ascii')\n",
    "  classVec = val[1][0].numpy()\n",
    "  print(image.shape)\n",
    "  ax = plt.subplot(4,4,n+1)\n",
    "  plt.text(1.1, 0.5, str(classVec),  \n",
    "          transform = ax.transAxes)\n",
    "  plt.imshow(image /255.0)\n",
    "#   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if 1:\n",
    "    imList = enumerate(tfDataset.take(6))\n",
    "    #??imList\n",
    "#     print(imList[0].shape())\n",
    "else:\n",
    "    v = next(tfDataset)\n",
    "    imList = [im for im in v[0][:6]]\n",
    "matrixImage = layoutLayersToOneImage(np.stack(imList), 3, margin)\n",
    "imshow(matrixImage);\n",
    "print(v[1][:6])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "net = controlObj.netWrapper._getNet()\n",
    "l = net.base_model.get_layer('conv_1')\n",
    "print(l.dtype)\n",
    "w = controlObj.netWrapper.getMultWeights('conv_1')\n",
    "print(w.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "controlObj.netWrapper.imageCache.maxMemory = 20 << 30\n",
    "controlObj.netWrapper.imageCache.maxLruSize = 20 << 10\n",
    "controlObj.netWrapper.setLearnRate(controlObj.netWrapper.getRecommendedLearnRate())\n",
    "# Warmup\n",
    "# controlObj.learnRate = 1e-3\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_23'])\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_22'])\n",
    "controlObj.netWrapper._getNet()\n",
    "# controlObj.netWrapper.saveState()\n",
    "# controlObj.curEpochNum = 20\n",
    "# controlObj.loadState(controlObj.curEpochNum)\n",
    "# print(controlObj.netWrapper.net.batchSize) #, controlObj.getTowerWeights())\n",
    "# controlObj.setTowerWeights([1, 1, 0, 0, 0,  1, 1, 0, 0, 0,  1, 1])\n",
    "controlObj.netWrapper.setBatchSize(128) \n",
    "# # Warmup\n",
    "# stepCount = 520\n",
    "# for i in range(80, stepCount, 5):\n",
    "#     controlObj.learnRate = 1e-10 + 2e-4 * i / stepCount\n",
    "#     controlObj.onDoItersPressed(500)\n",
    "\n",
    "controlObj.learnRate = 1.5e-4\n",
    "# for layerName in ['conv_11', 'conv_12', 'conv_13', 'conv_21']:\n",
    "#     controlObj.netWrapper.setLayerTrainable(layerName, False)\n",
    "# controlObj.onDoItersPressed(10000)\n",
    "# for layerName in ['conv_11', 'conv_12', 'conv_13', 'conv_21']:\n",
    "#     controlObj.netWrapper.setLayerTrainable(layerName, True)\n",
    "controlObj.onDoItersPressed(30000)\n",
    "# controlObj.netWrapper.setLayerTrainable('conv_11', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 1e-5\n",
    "controlObj.netWrapper.setBatchSize(128) \n",
    "# controlObj.loadState(243)\n",
    "controlObj.onDoItersPressed(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 1e-6\n",
    "controlObj.netWrapper.setBatchSize(128) \n",
    "controlObj.onDoItersPressed(30000)\n",
    "\n",
    "# controlObj.netWrapper.setLayerTrainable('conv_12', False)\n",
    "# controlObj.onDoItersPressed(5000)\n",
    "# controlObj.netWrapper.setLayerTrainable('conv_13', False)\n",
    "# controlObj.onDoItersPressed(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 1e-7\n",
    "controlObj.onDoItersPressed(70000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 1e-6\n",
    "controlObj.netWrapper.net.batchSize = 32\n",
    "controlObj.onDoItersPressed(15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlObj.curEpochNum = 310\n",
    "# controlObj.loadState(controlObj.curEpochNum)\n",
    "controlObj.learnRate = 1e-7\n",
    "controlObj.netWrapper.net.batchSize = 256\n",
    "controlObj.onDoItersPressed(15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseExcLayerNames = []\n",
    "for layer in controlObj.netWrapper.net.model.layers:\n",
    "    if layer.name.find('dense_exc_') == 0:\n",
    "        denseExcLayerNames.append(layer.name)\n",
    "        controlObj.netWrapper.setLayerTrainable(layer.name, False)\n",
    "controlObj.onDoItersPressed(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 5e-6\n",
    "controlObj.netWrapper.net.batchSize = 256\n",
    "controlObj.onDoItersPressed(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for controlObj.learnRate in reversed([9.e-4, 8e-4, 6.5e-4, 5e-4, 3.5e-4, 2.2e-4, 1.6e-4, 1.2e-4, 0.8e-4]):\n",
    "#     controlObj.onDoItersPressed(4000)    \n",
    "#     controlObj.curEpochNum = 265\n",
    "#     controlObj.loadState(controlObj.curEpochNum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for controlObj.learnRate in reversed([9.e-4, 8e-4, 6.5e-4, 5e-4, 3.5e-4, 2.2e-4, 1.6e-4, 1.2e-4, 0.8e-4]):\n",
    "#     controlObj.curEpochNum = 249\n",
    "#     controlObj.loadState(controlObj.curEpochNum)\n",
    "#     controlObj.onDoItersPressed(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 1e-5\n",
    "controlObj.netWrapper.net.batchSize = 256\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_1', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_2', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_3', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_1', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_2', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_3', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "# controlObj.onDoItersPressed(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 1e-6\n",
    "controlObj.netWrapper.setLayerTrainable('conv_1', False)\n",
    "controlObj.onDoItersPressed(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.curEpochNum = 120\n",
    "controlObj.loadState(controlObj.curEpochNum)\n",
    "controlObj.learnRate = 1e-4\n",
    "controlObj.onDoItersPressed(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 2.5e-4\n",
    "controlObj.curEpochNum = 290\n",
    "controlObj.loadState(controlObj.curEpochNum)\n",
    "controlObj.netWrapper.net.batchSize = 256\n",
    "controlObj.onDoItersPressed(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 1e-5\n",
    "controlObj.onDoItersPressed(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.curEpochNum = 150\n",
    "controlObj.loadState(controlObj.curEpochNum)\n",
    "controlObj.learnRate = 1e-4\n",
    "controlObj.onDoItersPressed(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(controlObj.netWrapper.getCacheStatusInfo(True))\n",
    "controlObj.learnRate = 1e-6\n",
    "controlObj.netWrapper.net.batchSize = 1024\n",
    "\n",
    "# controlObj.onDoItersPressed(15000)\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_3', 'dense_2'])\n",
    "controlObj.onDoItersPressed(8000)\n",
    "controlObj.netWrapper.net.batchSize = 256\n",
    "# controlObj.netWrapper.setLayerTrainable('conv_3', False)\n",
    "controlObj.onDoItersPressed(8000)\n",
    "\n",
    "controlObj.onDoItersPressed(3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    controlObj.netWrapper.setLearnRate(controlObj.netWrapper.getRecommendedLearnRate())\n",
    "    controlObj.netWrapper._initMainNet()\n",
    "    controlObj.learnRate = 9e-5\n",
    "    controlObj.netWrapper.net.batchSize = 128\n",
    "#     controlObj.loadState(335)\n",
    "    newW = 0.2\n",
    "    controlObj.setTowerWeights([newW, newW, 0.8, 0.8, 0,  newW, newW, 0.8, 0.8, 0,  1, 1])\n",
    "    for layerName in ['conv_11', 'conv_12', 'conv_13', 'conv_22']:\n",
    "        controlObj.netWrapper.setLayerTrainable(layerName, False)\n",
    "    for layerName in ['conv_12_2', 'conv_12_3', 'conv_13_2', 'conv_13_3']:\n",
    "        controlObj.netWrapper.setLayerTrainable(layerName, True)\n",
    "    \n",
    "    controlObj.onDoItersPressed(30000)\n",
    "    controlObj.learnRate = 1e-5\n",
    "    controlObj.onDoItersPressed(27000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlObj.netWrapper.imageCache.maxMemory = 4 << 30\n",
    "# controlObj.netWrapper.net.batchSize = 48\n",
    "\n",
    "controlObj.learnRate = 5e-7\n",
    "controlObj.onDoItersPressed(10000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_13', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_22', True)\n",
    "controlObj.onDoItersPressed(7000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', False)\n",
    "controlObj.onDoItersPressed(4000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_13', False)\n",
    "controlObj.onDoItersPressed(4000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "\n",
    "controlObj.learnRate = 1e-8\n",
    "controlObj.onDoItersPressed(10000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_1', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_23', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_2', False)\n",
    "controlObj.onDoItersPressed(100000)\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_3'])\n",
    "# controlObj.onDoItersPressed(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlObj.netWrapper.imageCache.clear()\n",
    "# controlObj.netWrapper.net.batchSize = 48\n",
    "\n",
    "controlObj.learnRate = 5e-7\n",
    "controlObj.onDoItersPressed(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "for i in range(3):\n",
    "    imshow(activations[i],cmap='Greys_r')   # Displays only one\n",
    "#display(activations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
