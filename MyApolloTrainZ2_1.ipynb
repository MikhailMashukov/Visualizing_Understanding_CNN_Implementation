{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0 [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# 14_4\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.getcwd()\n",
    "print(tf.__version__, tf.config.list_physical_devices('GPU'))\n",
    "# !pwd\n",
    "%matplotlib inline \n",
    "\n",
    "# from ipyexperiments import *\n",
    "# exp2 = IPyExperimentsPytorch()\n",
    "# from VisQtMain import *\n",
    "from VisJupyterNotUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !df -h\n",
    "# !cat /proc/cpuinfo\n",
    "# !top \n",
    "\n",
    "# import psutil\n",
    "\n",
    "# p = psutil.Process()\n",
    "# print(p.cpu_affinity())\n",
    "# p.cpu_affinity(range(0, 32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: -r not specified; omitting directory '/root/Visualiz_Zeiler/Data'\n",
      "cp: -r not specified; omitting directory '/root/Visualiz_Zeiler/ImageNetPart'\n",
      "cp: -r not specified; omitting directory '/root/Visualiz_Zeiler/QtLogs'\n",
      "cp: -r not specified; omitting directory '/root/Visualiz_Zeiler/__pycache__'\n",
      "AlexNetVisWrapper.py       MyImagesNetAnalysis.ipynb\n",
      "ChanConvModel.py           MyTrain1.ipynb\n",
      "ChanMatrixModel.py         MyUtils.py\n",
      "CorrelatAnalyzis.py        \u001b[0m\u001b[01;34mQtLogs\u001b[0m/\n",
      "\u001b[01;34mData\u001b[0m/                      SEResNeXt.py\n",
      "DataCache.py               VKIImageNetPart_TrainTestDivided.zip\n",
      "DeepOptions.py             VisColabUtils.py\n",
      "ImageModels.py             VisJupyterNotUtils.py\n",
      "ImageNet.py                VisQtMain.py\n",
      "\u001b[01;34mImageNetPart\u001b[0m/              VisUtils.py\n",
      "ImageNetsVisWrappers.py    \u001b[01;34m__pycache__\u001b[0m/\n",
      "MnistModel2.py             activations.py\n",
      "MnistModel5.py             alexnet.py\n",
      "MnistNet.py                alexnet_additional_layers.py\n",
      "MnistNetVisWrapper.py      alexnet_utils.py\n",
      "ModelUtils.py              decode_predictions.py\n",
      "MultActTops.py             deconvolution.py\n",
      "MyApolloImagesNetAn.ipynb  deconvolution_additional_layers.py\n",
      "MyApolloTrain1.ipynb       occlusion.py\n",
      "MyColabImagesNetAn.ipynb   validation.py\n",
      "MyColabTrain1.ipynb\n"
     ]
    }
   ],
   "source": [
    "# %rm -r ~/Visualiz_Zeiler/QtLogs/src\n",
    "%mkdir -p ~/Visualiz_Zeiler/QtLogs/src\n",
    "%cp -f ~/Visualiz_Zeiler/* ~/Visualiz_Zeiler/QtLogs/src/\n",
    "%ls ~/Visualiz_Zeiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99314207181c4e6e8160136db2d6780d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='x', max=15, min=-5), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "@interact   # Doesn't work now\n",
    "def f(x=5):\n",
    "    return x\n",
    "# interact(f, x=10);\n",
    "\n",
    "imageNum = 8\n",
    "image = controlObj.imageDataset.getImage(imageNum, 'cropped')\n",
    "# imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds from start (passed microseconds)\n",
      "-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 25, 25, 4, 96)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 227, 227, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 111, 111, 192 28416       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 74, 74, 192)  0           conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cross_chan_norm_120 (Lambda)    (None, 74, 74, 192)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cross_chan_norm_121 (Lambda)    (None, 74, 74, 192)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cross_chan_norm_122 (Lambda)    (None, 74, 74, 192)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 74, 74, 192)  768         cross_chan_norm_120[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 74, 74, 192)  768         cross_chan_norm_121[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 74, 74, 192)  768         cross_chan_norm_122[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 74, 74, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 74, 74, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 74, 74, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_12_0 (Conv2D)              (None, 35, 35, 192)  307392      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_12_1 (Conv2D)              (None, 35, 35, 192)  307392      lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_12_2 (Conv2D)              (None, 35, 35, 192)  307392      lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 35, 35, 192)  0           conv_12_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_2 (SpatialDro (None, 35, 35, 192)  0           conv_12_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_3 (SpatialDro (None, 35, 35, 192)  0           conv_12_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 35, 192)  768         spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 35, 35, 192)  768         spatial_dropout2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 192)  768         spatial_dropout2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_0 (Conv2D)              (None, 35, 35, 192)  331968      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_1 (Conv2D)              (None, 35, 35, 192)  331968      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_2 (Conv2D)              (None, 35, 35, 192)  331968      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_123_0 (Add)                 (None, 35, 35, 192)  0           spatial_dropout2d_1[0][0]        \n",
      "                                                                 conv_13_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_123_1 (Add)                 (None, 35, 35, 192)  0           spatial_dropout2d_2[0][0]        \n",
      "                                                                 conv_13_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_123_2 (Add)                 (None, 35, 35, 192)  0           spatial_dropout2d_3[0][0]        \n",
      "                                                                 conv_13_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 35, 35, 192)  0           add_123_0[0][0]                  \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 35, 35, 192)  0           add_123_1[0][0]                  \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 35, 35, 192)  0           add_123_2[0][0]                  \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_adds (Concatenate)       (None, 35, 35, 576)  0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 27, 27, 576)  0           conv_1_adds[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 27, 27, 576)  2304        lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 27, 27, 4, 14 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_22 (MaxPooling3D)      (None, 27, 27, 1, 14 0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 27, 27, 144)  0           max_pool_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv3D)                (None, 25, 25, 4, 96 124512      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 25, 25, 144)  0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 25, 25, 384)  0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_23 (Concatenate)         (None, 25, 25, 528)  0           cropping2d_1[0][0]               \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 19, 19, 528)  0           concat_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 19, 19, 528)  2112        lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 19, 19, 528)  2112        lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 19, 19, 528)  2112        lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 19, 19, 176)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 19, 19, 176)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 19, 19, 176)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_24_0 (Conv2D)              (None, 17, 17, 384)  608640      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_24_1 (Conv2D)              (None, 17, 17, 384)  608640      lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_24_2 (Conv2D)              (None, 17, 17, 384)  608640      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 17, 17, 384)  1536        conv_24_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 17, 17, 384)  1536        conv_24_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 17, 17, 384)  1536        conv_24_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cross_chan_norm_250 (Lambda)    (None, 17, 17, 384)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "cross_chan_norm_251 (Lambda)    (None, 17, 17, 384)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "cross_chan_norm_252 (Lambda)    (None, 17, 17, 384)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_25_0 (Conv2D)              (None, 17, 17, 384)  1327488     cross_chan_norm_250[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_25_1 (Conv2D)              (None, 17, 17, 384)  1327488     cross_chan_norm_251[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_25_2 (Conv2D)              (None, 17, 17, 384)  1327488     cross_chan_norm_252[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_4 (SpatialDro (None, 17, 17, 384)  0           conv_25_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_5 (SpatialDro (None, 17, 17, 384)  0           conv_25_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_6 (SpatialDro (None, 17, 17, 384)  0           conv_25_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_245_0 (Add)                 (None, 17, 17, 384)  0           conv_24_0[0][0]                  \n",
      "                                                                 spatial_dropout2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_245_1 (Add)                 (None, 17, 17, 384)  0           conv_24_1[0][0]                  \n",
      "                                                                 spatial_dropout2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_245_2 (Add)                 (None, 17, 17, 384)  0           conv_24_2[0][0]                  \n",
      "                                                                 spatial_dropout2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 17, 17, 384)  0           add_245_0[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 17, 17, 384)  0           add_245_1[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 17, 17, 384)  0           add_245_2[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_adds (Concatenate)       (None, 17, 17, 1152) 0           multiply_4[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 13, 13, 1152) 0           conv_2_adds[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 13, 13, 1152) 4608        lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 11, 11, 288)  2986272     batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_7 (SpatialDro (None, 11, 11, 288)  0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 8, 8, 288)    0           spatial_dropout2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 6, 6, 576)    1493568     lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 4, 4, 576)    0           conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 576)    2304        lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9216)         0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 192)          1769664     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 192)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 384)          74112       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 384)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 24)           9240        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 24)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 24)           0           lambda_19[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,237,016\n",
      "Trainable params: 14,224,632\n",
      "Non-trainable params: 12,384\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "12.408 (3278382.00) Activations: (1, 192, 111, 111), max 59.0703 ([0, 3, 41, 16])\n",
      "12.416 (  8731.00) (70, 111, 111) (902, 902)\n"
     ]
    }
   ],
   "source": [
    "epochNum = -3\n",
    "print(controlObj.getSelectedEpochNum())\n",
    "layerName = 'conv_11'\n",
    "activations, drawMode, stdData = controlObj.getActivationsData(epochNum, imageNum, layerName)\n",
    "actImage = layoutLayersToOneImage(np.sqrt(activations), colCount, margin)\n",
    "print(activations.shape, actImage.shape)\n",
    "imshow(actImage);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(0):\n",
    "    activations = controlObj.netWrapper.getImageActivations('dense_2', i, epochNum)\n",
    "    print(activations);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "  return image\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)\n",
    "def load_and_preprocess_image_with_label(path, label):\n",
    "  print(path)\n",
    "  image = tf.io.read_file(path)\n",
    "  print(image, label)\n",
    "  return preprocess_image(image), label\n",
    "\n",
    "all_image_paths = [\"ImageNetPart/American crow/1003355_8d39d66686.jpg\", \n",
    "                   \"ImageNetPart/barn owl/101715431_19d0b37108.jpg\"]\n",
    "labels = ['crow', 'owl']\n",
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=1)\n",
    "# for n, image in enumerate(load_image_ds.take(7)):\n",
    "#     print(image)\n",
    "    \n",
    "label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "# ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "# for n, v in enumerate(ds.take(7)):\n",
    "#     print(v)\n",
    "ds = ds.repeat()\n",
    "# ds = ds.map(load_and_preprocess_image_with_label, num_parallel_calls=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Internal dataset's check\n",
    "ds = controlObj.imageDataset.getTfDataset('test') \n",
    "# print(ds)\n",
    "plt.figure(figsize=(8,8))\n",
    "for n, val in enumerate(ds.take(3)):\n",
    "    # ??val\n",
    "#     print(val)\n",
    "    imageNum = val[0].numpy()\n",
    "    # classInd = val[1].numpy()\n",
    "    classInd = val[1].numpy()\n",
    "#     if imageNum % 1000 == 0:\n",
    "#         print(val)\n",
    "#     continue\n",
    "    className = controlObj.imageDataset.getClassNameLabel(classInd) #.decode('ascii')\n",
    "#     print(image.numpy().shape)\n",
    "    ax = plt.subplot(4,4,n+1)\n",
    "    plt.text(1.1, 0.5, '%s (%s)' % (className, str(classInd)),  \n",
    "          transform = ax.transAxes)\n",
    "    image = controlObj.imageDataset.getImage(imageNum, 'cropped', 'test')\n",
    "    plt.imshow(image / 255.0)\n",
    "    #   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Final (batched) datasets' check\n",
    "trainImageNums = np.arange(1, controlObj.imageDataset.getImageCount('train') + 1)\n",
    "testImageNums = np.arange(1, controlObj.imageDataset.getImageCount('test') + 1)\n",
    "tfTrainDataset, tfTestDataset = controlObj.netWrapper.net._getTfDatasets(\n",
    "                trainImageNums, testImageNums, 1000)\n",
    "# tfDataset = tf.compat.v1.data.make_one_shot_iterator(tfDataset)\n",
    "# ??tfDataset\n",
    "\n",
    "print(controlObj.imageDataset.getImageCount('train'))\n",
    "if 1:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for n, val in enumerate(tfTrainDataset.take(2)):\n",
    "        print(controlObj.netWrapper.getCacheStatusInfo(True))\n",
    "        images = val[0].numpy()\n",
    "    #     ??images\n",
    "        print(images.shape)\n",
    "        matrixImage = layoutLayersToOneImage(images, colCount, margin)\n",
    "        imshow(matrixImage);\n",
    "    #     imshow(images[0])\n",
    "        plt.show()\n",
    "\n",
    "if 0:\n",
    " for n, val in enumerate(tfDataset.take(0)):\n",
    "  # ??val\n",
    "  image = val[0][0].numpy()\n",
    "  # classInd = val[1].numpy()\n",
    "  # className = controlObj.imageDataset.getClassNameByInd(classInd) #.decode('ascii')\n",
    "  classVec = val[1][0].numpy()\n",
    "  print(image.shape)\n",
    "  ax = plt.subplot(4,4,n+1)\n",
    "  plt.text(1.1, 0.5, str(classVec),  \n",
    "          transform = ax.transAxes)\n",
    "  plt.imshow(image /255.0)\n",
    "#   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if 1:\n",
    "    imList = enumerate(tfDataset.take(6))\n",
    "    #??imList\n",
    "#     print(imList[0].shape())\n",
    "else:\n",
    "    v = next(tfDataset)\n",
    "    imList = [im for im in v[0][:6]]\n",
    "matrixImage = layoutLayersToOneImage(np.stack(imList), 3, margin)\n",
    "imshow(matrixImage);\n",
    "print(v[1][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.474 ( 57794.00) 160\n",
      "12.478 (  3476.00) Cur control object epoch 0, wrapper - -2\n",
      "12.504 ( 26629.00) Learning rate switched to 0.000090\n",
      "Epoch 1/1\n",
      " - 53s - loss: 0.0515 - accuracy: 0.0281 - val_loss: 0.0400 - val_accuracy: 0.0234\n",
      "115.245 (102740839.00) acts: 9.02 MBs, images: 3168 object(s), 34 + 0 in LRU lists, 550.52 MBs\n",
      "115.424 (178440.00) Epoch 1: loss 0.05150, acc 0.0281, last 1 epochs: 59.2430 s\n",
      "Epoch 2/2\n",
      " - 43s - loss: 0.0505 - accuracy: 0.0333 - val_loss: 0.0400 - val_accuracy: 0.0234\n",
      "196.763 (81339356.00) acts: 9.02 MBs, images: 5520 object(s), 867 + 0 in LRU lists, 965.59 MBs\n",
      "196.924 (161060.00) Epoch 2: loss 0.05051, acc 0.0333, last 1 epochs: 42.9095 s\n",
      "Epoch 3/3\n",
      " - 43s - loss: 0.0491 - accuracy: 0.0365 - val_loss: 0.0399 - val_accuracy: 0.0156\n",
      "275.479 (78555135.00) acts: 9.02 MBs, images: 7344 object(s), 1960 + 0 in LRU lists, 1291.24 MBs\n",
      "275.637 (157828.00) Epoch 3: loss 0.04914, acc 0.0365, last 1 epochs: 42.9466 s\n",
      "Epoch 4/4\n",
      " - 43s - loss: 0.0483 - accuracy: 0.0510 - val_loss: 0.0399 - val_accuracy: 0.0703\n",
      "352.157 (76520505.00) acts: 9.02 MBs, images: 8829 object(s), 3103 + 0 in LRU lists, 1558.98 MBs\n",
      "352.311 (153995.00) Epoch 4: loss 0.04827, acc 0.0510, last 1 epochs: 42.8134 s\n",
      "Epoch 5/5\n",
      " - 87s - loss: 0.0478 - accuracy: 0.0292 - val_loss: 0.0400 - val_accuracy: 0.0406\n",
      "481.671 (129359417.00) acts: 9.02 MBs, images: 10481 object(s), 4700 + 0 in LRU lists, 1861.27 MBs\n",
      "481.821 (150139.00) Epoch 5: loss 0.04778, acc 0.0292, last 1 epochs: 86.5674 s\n",
      "Epoch 6/6\n",
      " - 170s - loss: 0.0457 - accuracy: 0.0416 - val_loss: 0.0400 - val_accuracy: 0.0437\n",
      "713.036 (231214624.00) acts: 9.02 MBs, images: 12369 object(s), 3472 + 5120 in LRU lists, 2209.58 MBs\n",
      "713.186 (150483.00) Epoch 6: loss 0.04571, acc 0.0416, last 1 epochs: 170.5249 s\n",
      "Epoch 7/7\n",
      " - 343s - loss: 0.0442 - accuracy: 0.0415 - val_loss: 0.0399 - val_accuracy: 0.0430\n",
      "1148.025 (434838975.00) acts: 9.02 MBs, images: 14191 object(s), 1122 + 5120 in LRU lists, 2546.96 MBs\n",
      "1148.173 (148211.00) Epoch 7: loss 0.04418, acc 0.0415, last 1 epochs: 342.5741 s\n",
      "Epoch 8/8\n",
      " - 429s - loss: 0.0423 - accuracy: 0.0387 - val_loss: 0.0399 - val_accuracy: 0.0463\n",
      "1680.261 (532087970.00) acts: 9.02 MBs, images: 14958 object(s), 2235 + 5120 in LRU lists, 2689.01 MBs\n",
      "1680.450 (188310.00) Epoch 8: loss 0.04230, acc 0.0387, last 1 epochs: 429.4879 s\n",
      "Epoch 9/9\n",
      " - 429s - loss: 0.0412 - accuracy: 0.0476 - val_loss: 0.0400 - val_accuracy: 0.0499\n",
      "2207.386 (526936756.00) acts: 9.02 MBs, images: 15209 object(s), 3736 + 5120 in LRU lists, 2735.19 MBs\n",
      "2207.551 (164549.00) Epoch 9: loss 0.04117, acc 0.0476, last 1 epochs: 428.6167 s\n",
      "Epoch 10/10\n",
      " - 430s - loss: 0.0407 - accuracy: 0.0442 - val_loss: 0.0399 - val_accuracy: 0.0733\n",
      "2733.591 (526040193.00) acts: 9.02 MBs, images: 15288 object(s), 225 + 5120 in LRU lists, 2749.80 MBs\n",
      "2733.740 (148870.00) Epoch 10: loss 0.04075, acc 0.0442, last 1 epochs: 429.5828 s\n",
      "Epoch 11/11\n",
      " - 429s - loss: 0.0405 - accuracy: 0.0519 - val_loss: 0.0399 - val_accuracy: 0.0986\n",
      "3258.922 (525181547.00) Epoch 11: loss 0.04046, acc 0.0519, last 1 epochs: 429.2297 s\n",
      "Epoch 12/12\n",
      " - 430s - loss: 0.0402 - accuracy: 0.0605 - val_loss: 0.0396 - val_accuracy: 0.1250\n",
      "3784.607 (525685273.00) Epoch 12: loss 0.04024, acc 0.0605, last 1 epochs: 430.2193 s\n",
      "Epoch 13/13\n",
      " - 430s - loss: 0.0400 - accuracy: 0.0800 - val_loss: 0.0399 - val_accuracy: 0.1346\n",
      "4309.975 (525368175.00) Epoch 13: loss 0.03997, acc 0.0800, last 1 epochs: 429.7719 s\n",
      "Epoch 14/14\n",
      " - 429s - loss: 0.0398 - accuracy: 0.0875 - val_loss: 0.0385 - val_accuracy: 0.1490\n",
      "4834.550 (524575095.00) Epoch 14: loss 0.03977, acc 0.0875, last 1 epochs: 429.3650 s\n",
      "Epoch 15/15\n",
      " - 431s - loss: 0.0396 - accuracy: 0.1025 - val_loss: 0.0386 - val_accuracy: 0.1472\n",
      "5361.611 (527060997.00) Epoch 15: loss 0.03955, acc 0.1025, last 1 epochs: 431.1030 s\n",
      "Epoch 16/16\n",
      " - 430s - loss: 0.0393 - accuracy: 0.1206 - val_loss: 0.0390 - val_accuracy: 0.1899\n",
      "5888.468 (526856614.00) Epoch 16: loss 0.03928, acc 0.1206, last 1 epochs: 429.6573 s\n",
      "Epoch 17/17\n",
      " - 429s - loss: 0.0391 - accuracy: 0.1298 - val_loss: 0.0385 - val_accuracy: 0.1653\n",
      "6413.264 (524796713.00) Epoch 17: loss 0.03907, acc 0.1298, last 1 epochs: 428.9816 s\n",
      "Epoch 18/18\n",
      " - 430s - loss: 0.0389 - accuracy: 0.1372 - val_loss: 0.0359 - val_accuracy: 0.1731\n",
      "6940.087 (526822217.00) Epoch 18: loss 0.03888, acc 0.1372, last 1 epochs: 430.1257 s\n",
      "Epoch 19/19\n",
      " - 429s - loss: 0.0386 - accuracy: 0.1481 - val_loss: 0.0388 - val_accuracy: 0.1815\n",
      "7466.306 (526219298.00) Epoch 19: loss 0.03859, acc 0.1481, last 1 epochs: 429.4164 s\n",
      "Epoch 20/20\n",
      " - 429s - loss: 0.0383 - accuracy: 0.1653 - val_loss: 0.0381 - val_accuracy: 0.1917\n",
      "7992.496 (526190362.00) acts: 9.02 MBs, images: 15319 object(s), 3374 + 5120 in LRU lists, 2755.42 MBs\n",
      "7992.641 (144937.00) Epoch 20: loss 0.03829, acc 0.1653, last 1 epochs: 429.4431 s\n",
      "Epoch 21/21\n",
      " - 429s - loss: 0.0383 - accuracy: 0.1687 - val_loss: 0.0364 - val_accuracy: 0.2007\n",
      "8518.333 (525691595.00) Epoch 21: loss 0.03827, acc 0.1687, last 1 epochs: 429.3550 s\n",
      "Epoch 22/22\n",
      " - 430s - loss: 0.0383 - accuracy: 0.1708 - val_loss: 0.0365 - val_accuracy: 0.2278\n",
      "9043.761 (525428123.00) Epoch 22: loss 0.03827, acc 0.1708, last 1 epochs: 429.6345 s\n",
      "Epoch 23/23\n",
      " - 430s - loss: 0.0380 - accuracy: 0.1764 - val_loss: 0.0364 - val_accuracy: 0.2374\n",
      "9570.724 (526962955.00) Epoch 23: loss 0.03803, acc 0.1764, last 1 epochs: 430.1193 s\n",
      "Epoch 24/24\n",
      " - 430s - loss: 0.0379 - accuracy: 0.1777 - val_loss: 0.0354 - val_accuracy: 0.2290\n",
      "10097.011 (526286950.00) Epoch 24: loss 0.03794, acc 0.1777, last 1 epochs: 429.7187 s\n",
      "Epoch 25/25\n",
      " - 428s - loss: 0.0376 - accuracy: 0.1895 - val_loss: 0.0345 - val_accuracy: 0.2308\n",
      "10622.148 (525137478.00) Epoch 25: loss 0.03761, acc 0.1895, last 1 epochs: 428.4665 s\n",
      "Epoch 26/26\n",
      " - 430s - loss: 0.0376 - accuracy: 0.1941 - val_loss: 0.0371 - val_accuracy: 0.2464\n",
      "11146.124 (523975998.00) Epoch 26: loss 0.03756, acc 0.1941, last 1 epochs: 429.5812 s\n",
      "Epoch 27/27\n",
      " - 430s - loss: 0.0375 - accuracy: 0.1942 - val_loss: 0.0360 - val_accuracy: 0.2644\n",
      "11671.597 (525473000.00) Epoch 27: loss 0.03754, acc 0.1942, last 1 epochs: 429.7383 s\n",
      "Epoch 28/28\n",
      " - 428s - loss: 0.0372 - accuracy: 0.2041 - val_loss: 0.0349 - val_accuracy: 0.2356\n",
      "12196.548 (524950649.00) Epoch 28: loss 0.03725, acc 0.2041, last 1 epochs: 428.2382 s\n",
      "Epoch 29/29\n",
      " - 428s - loss: 0.0372 - accuracy: 0.2089 - val_loss: 0.0365 - val_accuracy: 0.2524\n",
      "12720.974 (524425771.00) Epoch 29: loss 0.03724, acc 0.2089, last 1 epochs: 427.8589 s\n",
      "Epoch 30/30\n",
      " - 429s - loss: 0.0372 - accuracy: 0.2102 - val_loss: 0.0329 - val_accuracy: 0.2476\n",
      "13245.778 (524804109.00) acts: 9.02 MBs, images: 15319 object(s), 1175 + 5120 in LRU lists, 2755.42 MBs\n",
      "13245.924 (145789.00) Epoch 30: loss 0.03720, acc 0.2102, last 1 epochs: 428.7496 s\n",
      "Epoch 31/31\n",
      " - 429s - loss: 0.0370 - accuracy: 0.2134 - val_loss: 0.0364 - val_accuracy: 0.2620\n",
      "13770.575 (524651266.00) Epoch 31: loss 0.03701, acc 0.2134, last 1 epochs: 429.2160 s\n",
      "Epoch 32/32\n",
      " - 428s - loss: 0.0368 - accuracy: 0.2169 - val_loss: 0.0357 - val_accuracy: 0.2584\n",
      "14294.882 (524306973.00) Epoch 32: loss 0.03678, acc 0.2169, last 1 epochs: 428.4681 s\n",
      "Epoch 33/33\n",
      " - 429s - loss: 0.0368 - accuracy: 0.2268 - val_loss: 0.0358 - val_accuracy: 0.2488\n",
      "14818.377 (523495496.00) Epoch 33: loss 0.03678, acc 0.2268, last 1 epochs: 428.9895 s\n",
      "Epoch 34/34\n",
      " - 429s - loss: 0.0367 - accuracy: 0.2285 - val_loss: 0.0335 - val_accuracy: 0.2752\n",
      "15343.192 (524814221.00) Epoch 34: loss 0.03669, acc 0.2285, last 1 epochs: 429.1602 s\n",
      "Epoch 35/35\n",
      " - 429s - loss: 0.0364 - accuracy: 0.2312 - val_loss: 0.0344 - val_accuracy: 0.2927\n",
      "15866.799 (523607063.00) Epoch 35: loss 0.03644, acc 0.2312, last 1 epochs: 428.7808 s\n",
      "Epoch 36/36\n",
      " - 429s - loss: 0.0364 - accuracy: 0.2386 - val_loss: 0.0342 - val_accuracy: 0.2885\n",
      "16391.893 (525094072.00) Epoch 36: loss 0.03636, acc 0.2386, last 1 epochs: 429.0763 s\n",
      "Epoch 37/37\n",
      " - 430s - loss: 0.0361 - accuracy: 0.2503 - val_loss: 0.0330 - val_accuracy: 0.2891\n",
      "16916.079 (524185786.00) Epoch 37: loss 0.03606, acc 0.2503, last 1 epochs: 429.5679 s\n",
      "Epoch 38/38\n",
      " - 429s - loss: 0.0360 - accuracy: 0.2457 - val_loss: 0.0341 - val_accuracy: 0.2903\n",
      "17441.936 (525857426.00) Epoch 38: loss 0.03603, acc 0.2457, last 1 epochs: 429.3738 s\n",
      "Epoch 39/39\n",
      " - 430s - loss: 0.0359 - accuracy: 0.2541 - val_loss: 0.0338 - val_accuracy: 0.2819\n",
      "17968.128 (526191905.00) Epoch 39: loss 0.03591, acc 0.2541, last 1 epochs: 430.0387 s\n",
      "Epoch 40/40\n",
      " - 429s - loss: 0.0357 - accuracy: 0.2581 - val_loss: 0.0339 - val_accuracy: 0.2825\n",
      "18493.297 (525168766.00) acts: 9.02 MBs, images: 15319 object(s), 4114 + 5120 in LRU lists, 2755.42 MBs\n",
      "18493.474 (177812.00) Epoch 40: loss 0.03571, acc 0.2581, last 1 epochs: 429.1075 s\n",
      "Epoch 41/41\n",
      " - 428s - loss: 0.0354 - accuracy: 0.2651 - val_loss: 0.0325 - val_accuracy: 0.3017\n",
      "19015.660 (522185107.00) Epoch 41: loss 0.03544, acc 0.2651, last 1 epochs: 427.7128 s\n",
      "Epoch 42/42\n",
      " - 429s - loss: 0.0357 - accuracy: 0.2582 - val_loss: 0.0335 - val_accuracy: 0.2987\n",
      "19539.698 (524038073.00) Epoch 42: loss 0.03569, acc 0.2582, last 1 epochs: 429.0845 s\n",
      "Epoch 43/43\n",
      " - 429s - loss: 0.0354 - accuracy: 0.2673 - val_loss: 0.0309 - val_accuracy: 0.3107\n",
      "20063.000 (523302295.00) Epoch 43: loss 0.03540, acc 0.2673, last 1 epochs: 428.5574 s\n",
      "Epoch 44/44\n",
      " - 429s - loss: 0.0356 - accuracy: 0.2591 - val_loss: 0.0342 - val_accuracy: 0.3011\n",
      "20587.288 (524287793.00) Epoch 44: loss 0.03556, acc 0.2591, last 1 epochs: 428.6166 s\n",
      "Epoch 45/45\n",
      " - 430s - loss: 0.0355 - accuracy: 0.2682 - val_loss: 0.0352 - val_accuracy: 0.2837\n",
      "21112.646 (525358598.00) Epoch 45: loss 0.03550, acc 0.2682, last 1 epochs: 429.8437 s\n",
      "Epoch 46/46\n",
      " - 429s - loss: 0.0352 - accuracy: 0.2716 - val_loss: 0.0361 - val_accuracy: 0.2933\n",
      "21637.885 (525238671.00) Epoch 46: loss 0.03521, acc 0.2716, last 1 epochs: 428.7268 s\n",
      "Epoch 47/47\n",
      " - 429s - loss: 0.0350 - accuracy: 0.2755 - val_loss: 0.0348 - val_accuracy: 0.3089\n",
      "22163.294 (525409075.00) Epoch 47: loss 0.03504, acc 0.2755, last 1 epochs: 428.9374 s\n",
      "Epoch 48/48\n",
      " - 429s - loss: 0.0351 - accuracy: 0.2773 - val_loss: 0.0349 - val_accuracy: 0.3083\n",
      "22687.184 (523889481.00) Epoch 48: loss 0.03513, acc 0.2773, last 1 epochs: 429.0791 s\n",
      "Epoch 49/49\n",
      " - 429s - loss: 0.0352 - accuracy: 0.2705 - val_loss: 0.0324 - val_accuracy: 0.3221\n",
      "23211.076 (523892564.00) Epoch 49: loss 0.03523, acc 0.2705, last 1 epochs: 428.6304 s\n",
      "Epoch 50/50\n",
      " - 428s - loss: 0.0351 - accuracy: 0.2735 - val_loss: 0.0326 - val_accuracy: 0.3137\n",
      "23734.169 (523092843.00) acts: 9.02 MBs, images: 15319 object(s), 1840 + 5120 in LRU lists, 2755.42 MBs\n",
      "23734.318 (149512.00) Epoch 50: loss 0.03510, acc 0.2735, last 1 epochs: 428.3783 s\n",
      "Epoch 51/51\n",
      " - 428s - loss: 0.0348 - accuracy: 0.2868 - val_loss: 0.0330 - val_accuracy: 0.3191\n",
      "24258.959 (524640284.00) Epoch 51: loss 0.03476, acc 0.2868, last 1 epochs: 428.5279 s\n",
      "Epoch 52/52\n",
      " - 427s - loss: 0.0345 - accuracy: 0.2911 - val_loss: 0.0338 - val_accuracy: 0.3323\n",
      "24782.018 (523059381.00) Epoch 52: loss 0.03448, acc 0.2911, last 1 epochs: 427.3240 s\n",
      "Epoch 53/53\n",
      " - 428s - loss: 0.0346 - accuracy: 0.2863 - val_loss: 0.0299 - val_accuracy: 0.3383\n",
      "25305.932 (523913545.00) Epoch 53: loss 0.03459, acc 0.2863, last 1 epochs: 428.4592 s\n",
      "Epoch 54/54\n",
      " - 429s - loss: 0.0345 - accuracy: 0.2955 - val_loss: 0.0338 - val_accuracy: 0.3239\n",
      "25831.207 (525275033.00) Epoch 54: loss 0.03446, acc 0.2955, last 1 epochs: 428.8707 s\n",
      "Epoch 55/55\n",
      " - 428s - loss: 0.0345 - accuracy: 0.2938 - val_loss: 0.0342 - val_accuracy: 0.3341\n",
      "26355.582 (524375773.00) Epoch 55: loss 0.03448, acc 0.2938, last 1 epochs: 428.1892 s\n",
      "Epoch 56/56\n",
      " - 429s - loss: 0.0343 - accuracy: 0.2974 - val_loss: 0.0339 - val_accuracy: 0.3389\n",
      "26881.246 (525663309.00) Epoch 56: loss 0.03433, acc 0.2974, last 1 epochs: 428.7776 s\n",
      "Epoch 57/57\n",
      " - 429s - loss: 0.0343 - accuracy: 0.2946 - val_loss: 0.0342 - val_accuracy: 0.3774\n",
      "27405.272 (524026162.00) Epoch 57: loss 0.03432, acc 0.2946, last 1 epochs: 429.0220 s\n",
      "Epoch 58/58\n",
      " - 428s - loss: 0.0344 - accuracy: 0.2974 - val_loss: 0.0323 - val_accuracy: 0.3528\n",
      "27928.719 (523447136.00) Epoch 58: loss 0.03441, acc 0.2974, last 1 epochs: 428.1842 s\n",
      "Epoch 59/59\n",
      " - 429s - loss: 0.0342 - accuracy: 0.3043 - val_loss: 0.0269 - val_accuracy: 0.3522\n",
      "28453.125 (524406045.00) Epoch 59: loss 0.03417, acc 0.3043, last 1 epochs: 428.7672 s\n",
      "Epoch 60/60\n",
      " - 428s - loss: 0.0343 - accuracy: 0.2968 - val_loss: 0.0356 - val_accuracy: 0.3570\n",
      "28976.834 (523708642.00) acts: 9.02 MBs, images: 15319 object(s), 4679 + 5120 in LRU lists, 2755.42 MBs\n",
      "28976.982 (148716.00) Epoch 60: loss 0.03433, acc 0.2968, last 1 epochs: 428.5276 s\n",
      "Epoch 61/61\n",
      " - 430s - loss: 0.0337 - accuracy: 0.3093 - val_loss: 0.0334 - val_accuracy: 0.3395\n",
      "29502.179 (525197048.00) Epoch 61: loss 0.03371, acc 0.3093, last 1 epochs: 430.1891 s\n",
      "Epoch 62/62\n",
      " - 428s - loss: 0.0340 - accuracy: 0.3055 - val_loss: 0.0317 - val_accuracy: 0.3233\n",
      "30026.736 (524556545.00) Epoch 62: loss 0.03400, acc 0.3055, last 1 epochs: 428.5650 s\n",
      "Epoch 63/63\n",
      " - 429s - loss: 0.0335 - accuracy: 0.3148 - val_loss: 0.0326 - val_accuracy: 0.3600\n",
      "30552.144 (525408398.00) Epoch 63: loss 0.03354, acc 0.3148, last 1 epochs: 428.9903 s\n",
      "Epoch 64/64\n",
      " - 430s - loss: 0.0339 - accuracy: 0.3106 - val_loss: 0.0332 - val_accuracy: 0.3480\n",
      "31077.655 (525510547.00) Epoch 64: loss 0.03386, acc 0.3106, last 1 epochs: 429.6274 s\n",
      "Epoch 65/65\n",
      " - 429s - loss: 0.0336 - accuracy: 0.3228 - val_loss: 0.0343 - val_accuracy: 0.3564\n",
      "31601.762 (524106718.00) Epoch 65: loss 0.03357, acc 0.3228, last 1 epochs: 428.7537 s\n",
      "Epoch 66/66\n",
      " - 429s - loss: 0.0338 - accuracy: 0.3165 - val_loss: 0.0301 - val_accuracy: 0.3401\n",
      "32124.876 (523114614.00) Epoch 66: loss 0.03376, acc 0.3165, last 1 epochs: 428.6680 s\n",
      "Epoch 67/67\n",
      " - 429s - loss: 0.0335 - accuracy: 0.3237 - val_loss: 0.0319 - val_accuracy: 0.3582\n",
      "32650.382 (525506033.00) Epoch 67: loss 0.03354, acc 0.3237, last 1 epochs: 429.3589 s\n",
      "Epoch 68/68\n",
      " - 430s - loss: 0.0335 - accuracy: 0.3180 - val_loss: 0.0308 - val_accuracy: 0.3504\n",
      "33176.069 (525686334.00) Epoch 68: loss 0.03353, acc 0.3180, last 1 epochs: 429.7210 s\n",
      "Epoch 69/69\n",
      " - 430s - loss: 0.0336 - accuracy: 0.3177 - val_loss: 0.0324 - val_accuracy: 0.3534\n",
      "33701.520 (525451587.00) Epoch 69: loss 0.03360, acc 0.3177, last 1 epochs: 429.8418 s\n",
      "Epoch 70/70\n",
      " - 430s - loss: 0.0330 - accuracy: 0.3264 - val_loss: 0.0286 - val_accuracy: 0.3642\n",
      "34226.922 (525401853.00) acts: 9.02 MBs, images: 15319 object(s), 2363 + 5120 in LRU lists, 2755.42 MBs\n",
      "34227.071 (148934.00) Epoch 70: loss 0.03302, acc 0.3264, last 1 epochs: 430.3718 s\n",
      "Epoch 71/71\n",
      " - 429s - loss: 0.0331 - accuracy: 0.3308 - val_loss: 0.0321 - val_accuracy: 0.3720\n",
      "34751.567 (524496206.00) Epoch 71: loss 0.03312, acc 0.3308, last 1 epochs: 429.0047 s\n",
      "Epoch 72/72\n",
      " - 429s - loss: 0.0333 - accuracy: 0.3224 - val_loss: 0.0296 - val_accuracy: 0.3786\n",
      "35276.695 (525127469.00) Epoch 72: loss 0.03333, acc 0.3224, last 1 epochs: 429.2679 s\n",
      "Epoch 73/73\n",
      " - 429s - loss: 0.0331 - accuracy: 0.3314 - val_loss: 0.0308 - val_accuracy: 0.3804\n",
      "35799.916 (523220946.00) Epoch 73: loss 0.03314, acc 0.3314, last 1 epochs: 428.8861 s\n",
      "Epoch 74/74\n",
      " - 429s - loss: 0.0332 - accuracy: 0.3244 - val_loss: 0.0317 - val_accuracy: 0.3636\n",
      "36323.015 (523099045.00) Epoch 74: loss 0.03324, acc 0.3244, last 1 epochs: 428.8532 s\n",
      "Epoch 75/75\n",
      " - 430s - loss: 0.0331 - accuracy: 0.3316 - val_loss: 0.0334 - val_accuracy: 0.3924\n",
      "36847.468 (524452912.00) Epoch 75: loss 0.03313, acc 0.3316, last 1 epochs: 429.6692 s\n",
      "Epoch 76/76\n",
      " - 429s - loss: 0.0330 - accuracy: 0.3322 - val_loss: 0.0314 - val_accuracy: 0.3546\n",
      "37370.956 (523488366.00) Epoch 76: loss 0.03300, acc 0.3322, last 1 epochs: 428.9762 s\n",
      "Epoch 77/77\n",
      " - 429s - loss: 0.0330 - accuracy: 0.3337 - val_loss: 0.0297 - val_accuracy: 0.3564\n",
      "37895.137 (524180567.00) Epoch 77: loss 0.03299, acc 0.3337, last 1 epochs: 429.3355 s\n",
      "Epoch 78/78\n",
      " - 428s - loss: 0.0329 - accuracy: 0.3353 - val_loss: 0.0355 - val_accuracy: 0.4008\n",
      "38418.388 (523250936.00) Epoch 78: loss 0.03294, acc 0.3353, last 1 epochs: 428.2227 s\n",
      "Epoch 79/79\n",
      " - 427s - loss: 0.0329 - accuracy: 0.3377 - val_loss: 0.0311 - val_accuracy: 0.3978\n",
      "38940.809 (522421953.00) Epoch 79: loss 0.03292, acc 0.3377, last 1 epochs: 427.5194 s\n",
      "Epoch 80/80\n",
      " - 429s - loss: 0.0325 - accuracy: 0.3485 - val_loss: 0.0321 - val_accuracy: 0.3954\n",
      "39465.220 (524410844.00) acts: 9.02 MBs, images: 15319 object(s), 4947 + 5120 in LRU lists, 2755.42 MBs\n",
      "39465.412 (191561.00) Epoch 80: loss 0.03252, acc 0.3485, last 1 epochs: 429.5316 s\n",
      "Epoch 81/81\n",
      " - 429s - loss: 0.0327 - accuracy: 0.3414 - val_loss: 0.0315 - val_accuracy: 0.4099\n",
      "39989.646 (524234069.00) Epoch 81: loss 0.03271, acc 0.3414, last 1 epochs: 429.1212 s\n",
      "Epoch 82/82\n",
      " - 429s - loss: 0.0325 - accuracy: 0.3445 - val_loss: 0.0299 - val_accuracy: 0.3900\n",
      "40514.909 (525262967.00) Epoch 82: loss 0.03249, acc 0.3445, last 1 epochs: 428.8607 s\n",
      "Epoch 83/83\n",
      " - 429s - loss: 0.0325 - accuracy: 0.3481 - val_loss: 0.0314 - val_accuracy: 0.4201\n",
      "41039.707 (524798444.00) Epoch 83: loss 0.03247, acc 0.3481, last 1 epochs: 429.4595 s\n",
      "Epoch 84/84\n",
      " - 429s - loss: 0.0325 - accuracy: 0.3504 - val_loss: 0.0283 - val_accuracy: 0.4020\n",
      "41564.054 (524346315.00) Epoch 84: loss 0.03246, acc 0.3504, last 1 epochs: 429.1231 s\n",
      "Epoch 85/85\n",
      " - 429s - loss: 0.0323 - accuracy: 0.3526 - val_loss: 0.0271 - val_accuracy: 0.4279\n",
      "42087.910 (523856658.00) Epoch 85: loss 0.03229, acc 0.3526, last 1 epochs: 428.8016 s\n",
      "Epoch 86/86\n",
      " - 428s - loss: 0.0323 - accuracy: 0.3495 - val_loss: 0.0299 - val_accuracy: 0.4195\n",
      "42611.081 (523170258.00) Epoch 86: loss 0.03227, acc 0.3495, last 1 epochs: 428.0711 s\n",
      "Epoch 87/87\n",
      " - 430s - loss: 0.0324 - accuracy: 0.3551 - val_loss: 0.0267 - val_accuracy: 0.4171\n",
      "43137.043 (525962185.00) Epoch 87: loss 0.03238, acc 0.3551, last 1 epochs: 430.4822 s\n",
      "Epoch 88/88\n",
      " - 429s - loss: 0.0324 - accuracy: 0.3529 - val_loss: 0.0306 - val_accuracy: 0.4056\n",
      "43661.100 (524057395.00) Epoch 88: loss 0.03238, acc 0.3529, last 1 epochs: 429.2737 s\n",
      "Epoch 89/89\n",
      " - 429s - loss: 0.0321 - accuracy: 0.3563 - val_loss: 0.0323 - val_accuracy: 0.3996\n",
      "44185.560 (524460144.00) Epoch 89: loss 0.03210, acc 0.3563, last 1 epochs: 429.4420 s\n",
      "Epoch 90/90\n",
      " - 429s - loss: 0.0319 - accuracy: 0.3603 - val_loss: 0.0314 - val_accuracy: 0.4273\n",
      "44710.415 (524854865.00) acts: 9.02 MBs, images: 15319 object(s), 3137 + 5120 in LRU lists, 2755.42 MBs\n",
      "44710.573 (157869.00) Epoch 90: loss 0.03193, acc 0.3603, last 1 epochs: 429.4854 s\n",
      "Epoch 91/91\n",
      " - 431s - loss: 0.0321 - accuracy: 0.3511 - val_loss: 0.0316 - val_accuracy: 0.4207\n",
      "45236.745 (526171878.00) Epoch 91: loss 0.03211, acc 0.3511, last 1 epochs: 431.0628 s\n",
      "Epoch 92/92\n",
      " - 429s - loss: 0.0320 - accuracy: 0.3625 - val_loss: 0.0285 - val_accuracy: 0.4159\n",
      "45760.931 (524185819.00) Epoch 92: loss 0.03200, acc 0.3625, last 1 epochs: 428.9102 s\n",
      "Epoch 93/93\n",
      " - 430s - loss: 0.0318 - accuracy: 0.3716 - val_loss: 0.0293 - val_accuracy: 0.4038\n",
      "46286.056 (525125721.00) Epoch 93: loss 0.03176, acc 0.3716, last 1 epochs: 430.0129 s\n",
      "Epoch 94/94\n",
      " - 430s - loss: 0.0321 - accuracy: 0.3623 - val_loss: 0.0264 - val_accuracy: 0.4291\n",
      "46810.472 (524415125.00) Epoch 94: loss 0.03214, acc 0.3623, last 1 epochs: 430.1712 s\n",
      "Epoch 95/95\n",
      " - 429s - loss: 0.0318 - accuracy: 0.3717 - val_loss: 0.0315 - val_accuracy: 0.4447\n",
      "47334.817 (524344922.00) Epoch 95: loss 0.03180, acc 0.3717, last 1 epochs: 429.5256 s\n",
      "Epoch 96/96\n",
      " - 429s - loss: 0.0316 - accuracy: 0.3763 - val_loss: 0.0309 - val_accuracy: 0.4417\n",
      "47860.365 (525548134.00) Epoch 96: loss 0.03160, acc 0.3763, last 1 epochs: 429.2719 s\n",
      "Epoch 97/97\n",
      " - 429s - loss: 0.0318 - accuracy: 0.3676 - val_loss: 0.0289 - val_accuracy: 0.4069\n",
      "48384.823 (524458370.00) Epoch 97: loss 0.03180, acc 0.3676, last 1 epochs: 429.2632 s\n",
      "Epoch 98/98\n",
      " - 429s - loss: 0.0316 - accuracy: 0.3710 - val_loss: 0.0256 - val_accuracy: 0.4369\n",
      "48908.684 (523861273.00) Epoch 98: loss 0.03164, acc 0.3710, last 1 epochs: 429.0823 s\n",
      "Epoch 99/99\n",
      " - 430s - loss: 0.0314 - accuracy: 0.3765 - val_loss: 0.0306 - val_accuracy: 0.4165\n",
      "49434.033 (525348935.00) Epoch 99: loss 0.03139, acc 0.3765, last 1 epochs: 430.1227 s\n",
      "Epoch 100/100\n",
      " - 429s - loss: 0.0314 - accuracy: 0.3744 - val_loss: 0.0292 - val_accuracy: 0.4117\n",
      "49957.878 (523844532.00) acts: 9.02 MBs, images: 15319 object(s), 827 + 5120 in LRU lists, 2755.42 MBs\n",
      "49958.024 (145871.00) Epoch 100: loss 0.03144, acc 0.3744, last 1 epochs: 428.8505 s\n",
      "Epoch 101/101\n",
      " - 430s - loss: 0.0314 - accuracy: 0.3763 - val_loss: 0.0291 - val_accuracy: 0.4062\n",
      "50483.159 (525135338.00) Epoch 101: loss 0.03136, acc 0.3763, last 1 epochs: 429.6381 s\n",
      "Epoch 102/102\n",
      " - 429s - loss: 0.0314 - accuracy: 0.3803 - val_loss: 0.0293 - val_accuracy: 0.4171\n",
      "51006.719 (523559924.00) Epoch 102: loss 0.03137, acc 0.3803, last 1 epochs: 429.0322 s\n",
      "Epoch 103/103\n",
      " - 429s - loss: 0.0313 - accuracy: 0.3762 - val_loss: 0.0292 - val_accuracy: 0.4243\n",
      "51530.430 (523710847.00) Epoch 103: loss 0.03135, acc 0.3762, last 1 epochs: 429.1359 s\n",
      "Epoch 104/104\n",
      " - 429s - loss: 0.0313 - accuracy: 0.3860 - val_loss: 0.0273 - val_accuracy: 0.4453\n",
      "52054.456 (524026204.00) Epoch 104: loss 0.03129, acc 0.3860, last 1 epochs: 428.5703 s\n",
      "Epoch 105/105\n",
      " - 429s - loss: 0.0315 - accuracy: 0.3735 - val_loss: 0.0313 - val_accuracy: 0.4357\n",
      "52578.292 (523835738.00) Epoch 105: loss 0.03155, acc 0.3735, last 1 epochs: 429.5310 s\n",
      "Epoch 106/106\n",
      " - 429s - loss: 0.0310 - accuracy: 0.3895 - val_loss: 0.0311 - val_accuracy: 0.4573\n",
      "53101.893 (523601261.00) Epoch 106: loss 0.03101, acc 0.3895, last 1 epochs: 428.9138 s\n",
      "Epoch 107/107\n",
      " - 430s - loss: 0.0312 - accuracy: 0.3863 - val_loss: 0.0283 - val_accuracy: 0.4393\n",
      "53626.115 (524221795.00) Epoch 107: loss 0.03116, acc 0.3863, last 1 epochs: 429.6094 s\n",
      "Epoch 108/108\n",
      " - 428s - loss: 0.0311 - accuracy: 0.3861 - val_loss: 0.0307 - val_accuracy: 0.4471\n",
      "54149.294 (523179604.00) Epoch 108: loss 0.03108, acc 0.3861, last 1 epochs: 428.1179 s\n",
      "Epoch 109/109\n",
      " - 429s - loss: 0.0310 - accuracy: 0.3900 - val_loss: 0.0286 - val_accuracy: 0.4375\n",
      "54673.349 (524055073.00) Epoch 109: loss 0.03102, acc 0.3900, last 1 epochs: 429.2166 s\n",
      "Epoch 110/110\n",
      " - 429s - loss: 0.0308 - accuracy: 0.3876 - val_loss: 0.0300 - val_accuracy: 0.4621\n",
      "55197.638 (524288241.00) acts: 9.02 MBs, images: 15319 object(s), 3646 + 5120 in LRU lists, 2755.42 MBs\n",
      "55197.785 (147336.00) Epoch 110: loss 0.03084, acc 0.3876, last 1 epochs: 429.0522 s\n",
      "Epoch 111/111\n",
      " - 431s - loss: 0.0307 - accuracy: 0.3943 - val_loss: 0.0253 - val_accuracy: 0.4255\n",
      "55725.147 (527361831.00) Epoch 111: loss 0.03071, acc 0.3943, last 1 epochs: 430.7457 s\n",
      "Epoch 112/112\n",
      " - 430s - loss: 0.0310 - accuracy: 0.3885 - val_loss: 0.0281 - val_accuracy: 0.4525\n",
      "56250.464 (525317330.00) Epoch 112: loss 0.03098, acc 0.3885, last 1 epochs: 430.0866 s\n",
      "Epoch 113/113\n",
      " - 430s - loss: 0.0306 - accuracy: 0.3995 - val_loss: 0.0259 - val_accuracy: 0.4700\n",
      "56775.646 (525181585.00) Epoch 113: loss 0.03059, acc 0.3995, last 1 epochs: 429.9826 s\n",
      "Epoch 114/114\n",
      " - 429s - loss: 0.0306 - accuracy: 0.3971 - val_loss: 0.0311 - val_accuracy: 0.4291\n",
      "57300.124 (524478702.00) Epoch 114: loss 0.03058, acc 0.3971, last 1 epochs: 429.3583 s\n",
      "Epoch 115/115\n",
      " - 431s - loss: 0.0304 - accuracy: 0.4019 - val_loss: 0.0290 - val_accuracy: 0.4453\n",
      "57826.618 (526493888.00) Epoch 115: loss 0.03044, acc 0.4019, last 1 epochs: 430.7944 s\n",
      "Epoch 116/116\n",
      " - 429s - loss: 0.0302 - accuracy: 0.4041 - val_loss: 0.0258 - val_accuracy: 0.4712\n",
      "58350.754 (524135463.00) Epoch 116: loss 0.03024, acc 0.4041, last 1 epochs: 429.0365 s\n",
      "Epoch 117/117\n",
      " - 431s - loss: 0.0305 - accuracy: 0.3969 - val_loss: 0.0298 - val_accuracy: 0.4459\n",
      "58876.796 (526041809.00) Epoch 117: loss 0.03055, acc 0.3969, last 1 epochs: 430.8472 s\n",
      "Epoch 118/118\n",
      " - 429s - loss: 0.0308 - accuracy: 0.4001 - val_loss: 0.0319 - val_accuracy: 0.4447\n",
      "59400.701 (523905786.00) Epoch 118: loss 0.03080, acc 0.4001, last 1 epochs: 428.8583 s\n",
      "Epoch 119/119\n",
      " - 429s - loss: 0.0303 - accuracy: 0.4017 - val_loss: 0.0316 - val_accuracy: 0.4321\n",
      "59924.931 (524229703.00) Epoch 119: loss 0.03035, acc 0.4017, last 1 epochs: 429.3772 s\n",
      "Epoch 120/120\n",
      " - 430s - loss: 0.0303 - accuracy: 0.4033 - val_loss: 0.0300 - val_accuracy: 0.4669\n",
      "60450.417 (525486401.00) acts: 9.02 MBs, images: 15319 object(s), 1453 + 5120 in LRU lists, 2755.42 MBs\n",
      "60450.612 (194242.00) Epoch 120: loss 0.03033, acc 0.4033, last 1 epochs: 429.9250 s\n",
      "Epoch 121/121\n",
      " - 430s - loss: 0.0302 - accuracy: 0.4051 - val_loss: 0.0276 - val_accuracy: 0.4651\n",
      "60976.888 (526276279.00) Epoch 121: loss 0.03019, acc 0.4051, last 1 epochs: 429.5824 s\n",
      "Epoch 122/122\n",
      " - 429s - loss: 0.0303 - accuracy: 0.4049 - val_loss: 0.0324 - val_accuracy: 0.4549\n",
      "61500.912 (524024067.00) Epoch 122: loss 0.03028, acc 0.4049, last 1 epochs: 429.5079 s\n",
      "Epoch 123/123\n"
     ]
    }
   ],
   "source": [
    "controlObj.netWrapper.imageCache.maxMemory = 4 << 30\n",
    "controlObj.learnRate = 9e-5\n",
    "print(controlObj.netWrapper.net.batchSize)\n",
    "controlObj.netWrapper.net.batchSize = 64\n",
    "# controlObj.netWrapper.setLearnRate(controlObj.netWrapper.getRecommendedLearnRate())\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_23'])\n",
    "# controlObj.netWrapper._initMainNet()\n",
    "controlObj.onDoItersPressed(10000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_11', False)\n",
    "controlObj.onDoItersPressed(7000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', False)\n",
    "controlObj.onDoItersPressed(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(controlObj.netWrapper.getCacheStatusInfo(True))\n",
    "controlObj.learnRate = 5e-6\n",
    "\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.doubleLayerWeights(['conv_22'])\n",
    "# controlObj.onDoItersPressed(3000)\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_3', 'dense_2'])\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_13', False)\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', False)\n",
    "controlObj.onDoItersPressed(3000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_22', False)\n",
    "controlObj.onDoItersPressed(3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlObj.netWrapper.imageCache.maxMemory = 4 << 30\n",
    "# controlObj.netWrapper.net.batchSize = 48\n",
    "\n",
    "controlObj.learnRate = 1e-7\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_13', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', True)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_22', True)\n",
    "controlObj.onDoItersPressed(20000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', False)\n",
    "controlObj.onDoItersPressed(10000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_3', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_1', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_23', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "# controlObj.netWrapper.doubleLayerWeights(['conv_4'])\n",
    "# controlObj.onDoItersPressed(20000)\n",
    "\n",
    "controlObj.learnRate = 1e-8\n",
    "controlObj.onDoItersPressed(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "for i in range(3):\n",
    "    imshow(activations[i],cmap='Greys_r')   # Displays only one\n",
    "#display(activations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImagesMatrix(data, col=2):\n",
    "    fig = figure( figsize=(600, 300))\n",
    "    number_of_files = len(data)\n",
    "    print(number_of_files)\n",
    "    row = number_of_files/col\n",
    "    if (number_of_files%col != 0):\n",
    "        row += 1\n",
    "    for i in range(number_of_files):\n",
    "        a=fig.add_subplot(row,col,i+1)\n",
    "        # image = imread(mypath+'/'+list_of_files[i])\n",
    "        axis('off')\n",
    "        print('Image %d drawn' % i)\n",
    "    # Very slow at the end\n",
    "        \n",
    "showImagesMatrix(activations[1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.permutation(600)[:4]:\n",
    "    count = count + 1\n",
    "    plt.subplot(1, sample_size, count)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image(filename=\"image/000644.jpg\", width=100, height=100)\n",
    "im.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![title](images/000644.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image          # Displaying of multiple images. To check\n",
    "from IPython.display import display\n",
    "x = Image(filename='1.png') \n",
    "y = Image(filename='2.png') \n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "with out:\n",
    "    display(widgets.IntSlider())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
