{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.getcwd()\n",
    "print(tf.__version__)\n",
    "# !pwd\n",
    "%matplotlib inline \n",
    "\n",
    "# from ipyexperiments import *\n",
    "# exp2 = IPyExperimentsPytorch()\n",
    "# from VisQtMain import *\n",
    "from VisJupyterNotUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm -r ~/Visualiz_Zeiler/QtLogs/src\n",
    "%mkdir ~/Visualiz_Zeiler/QtLogs/src\n",
    "%cp -f ~/Visualiz_Zeiler/* ~/Visualiz_Zeiler/QtLogs/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "@interact   # Doesn't work now\n",
    "def f(x=5):\n",
    "    return x\n",
    "# interact(f, x=10);\n",
    "\n",
    "imageNum = 8\n",
    "image = controlObj.imageDataset.getImage(imageNum, 'cropped')\n",
    "# imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochNum = -3\n",
    "print(controlObj.getSelectedEpochNum())\n",
    "layerName = 'conv_11'\n",
    "activations, drawMode, stdData = controlObj.getActivationsData(epochNum, imageNum, layerName)\n",
    "actImage = layoutLayersToOneImage(np.sqrt(activations), colCount, margin)\n",
    "print(activations.shape, actImage.shape)\n",
    "imshow(actImage);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    activations = controlObj.netWrapper.getImageActivations('dense_2', i, epochNum)\n",
    "    print(activations);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "  return image\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)\n",
    "def load_and_preprocess_image_with_label(path, label):\n",
    "  print(path)\n",
    "  image = tf.io.read_file(path)\n",
    "  print(image, label)\n",
    "  return preprocess_image(image), label\n",
    "\n",
    "all_image_paths = [\"ImageNetPart/American crow/1003355_8d39d66686.jpg\", \n",
    "                   \"ImageNetPart/barn owl/101715431_19d0b37108.jpg\"]\n",
    "labels = ['crow', 'owl']\n",
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=1)\n",
    "# for n, image in enumerate(load_image_ds.take(7)):\n",
    "#     print(image)\n",
    "    \n",
    "label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "# ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "# for n, v in enumerate(ds.take(7)):\n",
    "#     print(v)\n",
    "ds = ds.repeat()\n",
    "# ds = ds.map(load_and_preprocess_image_with_label, num_parallel_calls=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Internal dataset's check\n",
    "ds = controlObj.imageDataset.getTfDataset('test') \n",
    "# print(ds)\n",
    "plt.figure(figsize=(8,8))\n",
    "for n, val in enumerate(ds.take(3)):\n",
    "    # ??val\n",
    "#     print(val)\n",
    "    imageNum = val[0].numpy()\n",
    "    # classInd = val[1].numpy()\n",
    "    classInd = val[1].numpy()\n",
    "#     if imageNum % 1000 == 0:\n",
    "#         print(val)\n",
    "#     continue\n",
    "    className = controlObj.imageDataset.getClassNameLabel(classInd) #.decode('ascii')\n",
    "#     print(image.numpy().shape)\n",
    "    ax = plt.subplot(4,4,n+1)\n",
    "    plt.text(1.1, 0.5, '%s (%s)' % (className, str(classInd)),  \n",
    "          transform = ax.transAxes)\n",
    "    image = controlObj.imageDataset.getImage(imageNum, 'cropped', 'test')\n",
    "    plt.imshow(image / 255.0)\n",
    "    #   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Final (batched) datasets' check\n",
    "trainImageNums = np.arange(1, controlObj.imageDataset.getImageCount('train') + 1)\n",
    "testImageNums = np.arange(1, controlObj.imageDataset.getImageCount('test') + 1)\n",
    "tfTrainDataset, tfTestDataset = controlObj.netWrapper.net._getTfDatasets(\n",
    "                trainImageNums, testImageNums, 1000)\n",
    "# tfDataset = tf.compat.v1.data.make_one_shot_iterator(tfDataset)\n",
    "# ??tfDataset\n",
    "\n",
    "print(controlObj.imageDataset.getImageCount('train'))\n",
    "if 1:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for n, val in enumerate(tfTrainDataset.take(2)):\n",
    "        print(controlObj.netWrapper.getCacheStatusInfo(True))\n",
    "        images = val[0].numpy()\n",
    "    #     ??images\n",
    "        print(images.shape)\n",
    "        matrixImage = layoutLayersToOneImage(images, colCount, margin)\n",
    "        imshow(matrixImage);\n",
    "    #     imshow(images[0])\n",
    "        plt.show()\n",
    "\n",
    "if 0:\n",
    " for n, val in enumerate(tfDataset.take(0)):\n",
    "  # ??val\n",
    "  image = val[0][0].numpy()\n",
    "  # classInd = val[1].numpy()\n",
    "  # className = controlObj.imageDataset.getClassNameByInd(classInd) #.decode('ascii')\n",
    "  classVec = val[1][0].numpy()\n",
    "  print(image.shape)\n",
    "  ax = plt.subplot(4,4,n+1)\n",
    "  plt.text(1.1, 0.5, str(classVec),  \n",
    "          transform = ax.transAxes)\n",
    "  plt.imshow(image /255.0)\n",
    "#   plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if 1:\n",
    "    imList = enumerate(tfDataset.take(6))\n",
    "    #??imList\n",
    "#     print(imList[0].shape())\n",
    "else:\n",
    "    v = next(tfDataset)\n",
    "    imList = [im for im in v[0][:6]]\n",
    "matrixImage = layoutLayersToOneImage(np.stack(imList), 3, margin)\n",
    "imshow(matrixImage);\n",
    "print(v[1][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.netWrapper.imageCache.maxMemory = 4 << 30\n",
    "controlObj.learnRate = 5e-5\n",
    "print(controlObj.netWrapper.net.batchSize)\n",
    "controlObj.netWrapper.net.batchSize = 16\n",
    "controlObj.onDoItersPressed(2000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_11', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_12', False)\n",
    "controlObj.onDoItersPressed(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(controlObj.netWrapper.getCacheStatusInfo(True))\n",
    "controlObj.learnRate = 3e-6\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_13', False)\n",
    "controlObj.onDoItersPressed(25000)\n",
    "controlObj.learnRate = 5e-7\n",
    "controlObj.netWrapper.setLayerTrainable('conv_13', False)\n",
    "controlObj.onDoItersPressed(25000)\n",
    "\n",
    "\n",
    "controlObj.onDoItersPressed(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlObj.learnRate = 3e-6\n",
    "controlObj.onDoItersPressed(2000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.learnRate = 5e-7\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_22', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_23', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_24', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_3', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_4', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_1', False)\n",
    "controlObj.onDoItersPressed(25000)\n",
    "\n",
    "controlObj.learnRate = 8e-8\n",
    "controlObj.onDoItersPressed(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "controlObj.netWrapper.setLayerTrainable('conv_21', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_22', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_23', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_24', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_3', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('conv_4', False)\n",
    "controlObj.onDoItersPressed(5000)\n",
    "controlObj.netWrapper.setLayerTrainable('dense_1', False)\n",
    "controlObj.onDoItersPressed(25000)\n",
    "\n",
    "controlObj.learnRate = 8e-8\n",
    "controlObj.onDoItersPressed(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "for i in range(3):\n",
    "    imshow(activations[i],cmap='Greys_r')   # Displays only one\n",
    "#display(activations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImagesMatrix(data, col=2):\n",
    "    fig = figure( figsize=(600, 300))\n",
    "    number_of_files = len(data)\n",
    "    print(number_of_files)\n",
    "    row = number_of_files/col\n",
    "    if (number_of_files%col != 0):\n",
    "        row += 1\n",
    "    for i in range(number_of_files):\n",
    "        a=fig.add_subplot(row,col,i+1)\n",
    "        # image = imread(mypath+'/'+list_of_files[i])\n",
    "        axis('off')\n",
    "        print('Image %d drawn' % i)\n",
    "    # Very slow at the end\n",
    "        \n",
    "showImagesMatrix(activations[1:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.permutation(600)[:4]:\n",
    "    count = count + 1\n",
    "    plt.subplot(1, sample_size, count)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image(filename=\"image/000644.jpg\", width=100, height=100)\n",
    "im.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![title](images/000644.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image          # Displaying of multiple images. To check\n",
    "from IPython.display import display\n",
    "x = Image(filename='1.png') \n",
    "y = Image(filename='2.png') \n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "with out:\n",
    "    display(widgets.IntSlider())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 TensorFlow",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
