{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"intro_seg.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-r1Pac90eQ1R","colab_type":"text"},"source":["### FCN with Resnet-101 backbone"]},{"cell_type":"code","metadata":{"id":"jebN_lm9eQ1W","colab_type":"code","colab":{}},"source":["from torchvision import models\n","fcn = models.segmentation.fcn_resnet101(pretrained=True).eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"shnC_YQLeQ1v","colab_type":"code","colab":{}},"source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import torch\n","\n","!wget -nv https://static.independent.co.uk/s3fs-public/thumbnails/image/2018/04/10/19/pinyon-jay-bird.jpg -O bird.png\n","img = Image.open('./bird.png')\n","plt.imshow(img); plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8HUEYeNJeQ2N","colab_type":"code","colab":{}},"source":["# Apply the transformations needed\n","import torchvision.transforms as T\n","trf = T.Compose([T.Resize(256),\n","                 T.CenterCrop(224),\n","                 T.ToTensor(), \n","                 T.Normalize(mean = [0.485, 0.456, 0.406], \n","                             std = [0.229, 0.224, 0.225])])\n","inp = trf(img).unsqueeze(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QDujuCbeQ2h","colab_type":"code","colab":{}},"source":["# Pass the input through the net\n","out = fcn(inp)['out']\n","print (out.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEWJRobBeQ3A","colab_type":"code","colab":{}},"source":["import numpy as np\n","om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n","print (om.shape)\n","print (np.unique(om))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GA_GNohUHnR","colab_type":"code","colab":{}},"source":["# Define the helper function\n","def decode_segmap(image, nc=21):\n","  label_colors = np.array([(0, 0, 0),  # 0=background\n","               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n","               (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\n","               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n","               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n","               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n","               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n","               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n","               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n","\n","  r = np.zeros_like(image).astype(np.uint8)\n","  g = np.zeros_like(image).astype(np.uint8)\n","  b = np.zeros_like(image).astype(np.uint8)\n","  \n","  for l in range(0, nc):\n","    idx = image == l\n","    r[idx] = label_colors[l, 0]\n","    g[idx] = label_colors[l, 1]\n","    b[idx] = label_colors[l, 2]\n","    \n","  rgb = np.stack([r, g, b], axis=2)\n","  return rgb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"02LtJMO_eQ3c","colab_type":"code","colab":{}},"source":["rgb = decode_segmap(om)\n","plt.imshow(rgb); plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yTvVvX7eQ32","colab_type":"code","colab":{}},"source":["def segment(net, path, show_orig=True, dev='cuda'):\n","  img = Image.open(path)\n","  if show_orig: plt.imshow(img); plt.axis('off'); plt.show()\n","  # Comment the Resize and CenterCrop for better inference results\n","  trf = T.Compose([T.Resize(640), \n","                   #T.CenterCrop(224), \n","                   T.ToTensor(), \n","                   T.Normalize(mean = [0.485, 0.456, 0.406], \n","                               std = [0.229, 0.224, 0.225])])\n","  inp = trf(img).unsqueeze(0).to(dev)\n","  out = net.to(dev)(inp)['out']\n","  om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n","  rgb = decode_segmap(om)\n","  plt.imshow(rgb); plt.axis('off'); plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3hRnbZqbeQ4H","colab_type":"text"},"source":["And let's get a new image!"]},{"cell_type":"code","metadata":{"id":"wX7_viyieQ4K","colab_type":"code","colab":{}},"source":["!wget -nv \"https://www.recoveryranch.com/wp-content/uploads/2020/03/Horse-1200x900.jpg\" -O horse.jpeg\n","# !pwd\n","%ls . -l\n","# img = Image.open('horse.jpeg')\n","# plt.imshow(img)\n","segment(fcn, './horse.jpeg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZLo9m1nOeQ4W","colab_type":"text"},"source":["### DeepLabv3"]},{"cell_type":"code","metadata":{"id":"m_CLq1ZfeQ4b","colab_type":"code","colab":{}},"source":["dlab = models.segmentation.deeplabv3_resnet101(pretrained=1).eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60vz9GkBeQ4s","colab_type":"code","colab":{}},"source":["segment(dlab, './horse.jpeg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIVWe_asNECq","colab_type":"code","colab":{}},"source":["!wget -nv \"https://images.pexels.com/photos/1485799/pexels-photo-1485799.jpeg\" -O person.png\n","img = Image.open('./person.png')\n","plt.imshow(img); plt.show()\n","\n","print ('Segmenatation Image on FCN')\n","segment(fcn, path='./person.png', show_orig=False)\n","\n","print ('Segmenatation Image on DeepLabv3')\n","segment(dlab, path='./person.png', show_orig=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMn5yZJzg0Kw","colab_type":"text"},"source":["### Inference Time"]},{"cell_type":"code","metadata":{"id":"4fWw69Gk69Ri","colab_type":"code","colab":{}},"source":["import time\n","\n","def infer_time(net, path='./r.png', dev='cuda'):\n","  img = Image.open(path)\n","  trf = T.Compose([T.Resize(256), \n","                   T.CenterCrop(224), \n","                   T.ToTensor(), \n","                   T.Normalize(mean = [0.485, 0.456, 0.406], \n","                               std = [0.229, 0.224, 0.225])])\n","  \n","  inp = trf(img).unsqueeze(0).to(dev)\n","  \n","  st = time.time()\n","  out1 = net.to(dev)(inp)\n","  et = time.time()\n","  \n","  return et - st"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uxgc2DpH8NvQ","colab_type":"text"},"source":["**On CPU**"]},{"cell_type":"code","metadata":{"id":"yRzxN3J0hApt","colab_type":"code","colab":{}},"source":["avg_over = 100\n","\n","fcn_infer_time_list_cpu = [infer_time(fcn, dev='cpu') for _ in range(avg_over)]\n","fcn_infer_time_avg_cpu = sum(fcn_infer_time_list_cpu) / avg_over\n","\n","dlab_infer_time_list_cpu = [infer_time(dlab, dev='cpu') for _ in range(avg_over)]\n","dlab_infer_time_avg_cpu = sum(dlab_infer_time_list_cpu) / avg_over\n","\n","\n","print ('Inference time for first few calls for FCN      : {}'.format(fcn_infer_time_list_cpu[:10]))\n","print ('Inference time for first few calls for DeepLabv3: {}'.format(dlab_infer_time_list_cpu[:10]))\n","\n","print ('The Average Inference time on FCN is:     {:.2f}s'.format(fcn_infer_time_avg_cpu))\n","print ('The Average Inference time on DeepLab is: {:.2f}s'.format(dlab_infer_time_avg_cpu))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a2jCxTlphsYE","colab_type":"text"},"source":["**On GPU**"]},{"cell_type":"code","metadata":{"id":"sCpPUr8ViFB9","colab_type":"code","colab":{}},"source":["avg_over = 100\n","\n","fcn_infer_time_list_gpu = [infer_time(fcn) for _ in range(avg_over)]\n","fcn_infer_time_avg_gpu = sum(fcn_infer_time_list_gpu) / avg_over\n","\n","dlab_infer_time_list_gpu = [infer_time(dlab) for _ in range(avg_over)]\n","dlab_infer_time_avg_gpu = sum(dlab_infer_time_list_gpu) / avg_over\n","\n","print ('Inference time for first few calls for FCN      : {}'.format(fcn_infer_time_list_gpu[:10]))\n","print ('Inference time for first few calls for DeepLabv3: {}'.format(dlab_infer_time_list_gpu[:10]))\n","\n","print ('The Average Inference time on FCN is:     {:.3f}s'.format(fcn_infer_time_avg_gpu))\n","print ('The Average Inference time on DeepLab is: {:.3f}s'.format(dlab_infer_time_avg_gpu))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3dfTtJ79dqa","colab_type":"code","colab":{}},"source":["plt.bar([0.1, 0.2], [fcn_infer_time_avg_cpu, dlab_infer_time_avg_cpu], width=0.08)\n","plt.ylabel('Time taken in Seconds')\n","plt.xticks([0.1, 0.2], ['FCN', 'DeepLabv3'])\n","plt.title('Inference time of FCN and DeepLabv3 on CPU')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKBxG76tJdSo","colab_type":"code","colab":{}},"source":["plt.bar([0.1, 0.2], [fcn_infer_time_avg_gpu, dlab_infer_time_avg_gpu], width=0.08)\n","plt.ylabel('Time taken in Seconds')\n","plt.xticks([0.1, 0.2], ['FCN', 'DeepLabv3'])\n","plt.title('Inference time of FCN and DeepLabv3 on GPU')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s_eeF-rcKNpc","colab_type":"text"},"source":["Okay! Now, let's move on to the next comparison, where we will compare the model sizes for both the models."]},{"cell_type":"markdown","metadata":{"id":"0c7V8R_Xip5h","colab_type":"text"},"source":["### Model Size"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZhVyFg_4pQu4","colab":{}},"source":["import os\n","\n","resnet101_size = os.path.getsize('/root/.cache/torch/checkpoints/resnet101-5d3b4d8f.pth')\n","fcn_size = os.path.getsize('/root/.cache/torch/checkpoints/fcn_resnet101_coco-7ecb50ca.pth')\n","dlab_size = os.path.getsize('/root/.cache/torch/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth')\n","\n","fcn_total = fcn_size + resnet101_size\n","dlab_total = dlab_size + resnet101_size\n","    \n","print ('Size of the FCN model with Resnet101 backbone is:       {:.2f} MB'.format(fcn_total /  (1024 * 1024)))\n","print ('Size of the DeepLabv3 model with Resnet101 backbone is: {:.2f} MB'.format(dlab_total / (1024 * 1024)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwbeey11652y","colab_type":"code","colab":{}},"source":["plt.bar([0, 1], [fcn_total / (1024 * 1024), dlab_total / (1024 * 1024)])\n","plt.ylabel('Size of the model in MegaBytes')\n","plt.xticks([0, 1], ['FCN', 'DeepLabv3'])\n","plt.title('Comparison of the model size of FCN and DeepLabv3')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LdRkeAP0tU9d","colab_type":"text"},"source":["## Conclusion"]},{"cell_type":"markdown","metadata":{"id":"2AB5w01teQ4-","colab_type":"text"},"source":["Hope you enjoyed this tutorial!\n","\n","Feel free to leave comments and any feedback you wish! If you would like to learn<br/>\n","more about this, how these techniques work and how to implement these models!\n","\n","Please do check out the `Deep Learning with PyTorch` Course from OpenCV.org! <br/>\n","Link: https://opencv.org/ai-courses-by-opencv-kickstarter-campaign/"]},{"cell_type":"code","metadata":{"id":"ZxtABliMeQ5A","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}